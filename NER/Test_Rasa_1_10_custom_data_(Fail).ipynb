{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Rasa 1.10 - custom data (Fail).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPs19xKxcIvkBwux5QiFuJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/NLPlearning/blob/master/NER/Test_Rasa_1_10_custom_data_(Fail).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAPYjwi838rg",
        "colab_type": "text"
      },
      "source": [
        "# Train RASA_NLU with custom data\n",
        "\n",
        "In this notebook I test to train a RASA_NLU model with my own training data. But it always fails by Out of memory (OOM) error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNIXBt3XXWd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3tp_fWQtOkX",
        "colab_type": "text"
      },
      "source": [
        "## Train rasa_nlu by console\n",
        "\n",
        "[Blog](https://towardsdatascience.com/a-beginners-guide-to-rasa-nlu-for-intent-classification-and-named-entity-recognition-a4f0f76b2a96)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVyVGhlRwDxe",
        "colab_type": "text"
      },
      "source": [
        "* Setup and installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amyqjCpCgfNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rasa\n",
        "clear_output()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5C3lpliTgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U ipython\n",
        "clear_output()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82PP2BJe23pW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ea41fc18-cb8f-4d27-a018-ad92f322f8f9"
      },
      "source": [
        "import rasa\n",
        "rasa.__version__"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.12'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "633-s-dtv_99",
        "colab_type": "text"
      },
      "source": [
        "* Activate the virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8md3vdgmgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "2fdaacb5-c01d-4c50-af2c-c16a06f53489"
      },
      "source": [
        "! mkdir rasa\n",
        "%cd rasa\n",
        "! rasa init --no-prompt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rasa\n",
            "\u001b[92mWelcome to Rasa! ðŸ¤–\n",
            "\u001b[0m\n",
            "To get started quickly, an initial project will be created.\n",
            "If you need some help, check out the documentation at https://rasa.com/docs/rasa.\n",
            "\n",
            "Created project directory at '/content/rasa'.\n",
            "\u001b[92mFinished creating project structure.\u001b[0m\n",
            "\u001b[92mTraining an initial model...\u001b[0m\n",
            "\u001b[94mTraining Core model...\u001b[0m\n",
            "2020-09-03 11:33:37 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "2020-09-03 11:33:38 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "Processed Story Blocks: 100% 5/5 [00:00<00:00, 3338.88it/s, # trackers=1]\n",
            "Processed Story Blocks: 100% 5/5 [00:00<00:00, 1446.71it/s, # trackers=5]\n",
            "Processed Story Blocks: 100% 5/5 [00:00<00:00, 368.10it/s, # trackers=20]\n",
            "Processed Story Blocks: 100% 5/5 [00:00<00:00, 245.60it/s, # trackers=24]\n",
            "Processed trackers: 100% 5/5 [00:00<00:00, 2093.80it/s, # actions=16]\n",
            "Processed actions: 16it [00:00, 6398.02it/s, # examples=16]\n",
            "Processed trackers: 100% 231/231 [00:00<00:00, 427.61it/s, # actions=126]\n",
            "Epochs: 100% 100/100 [00:16<00:00,  5.93it/s, t_loss=0.085, loss=0.012, acc=1.000]\n",
            "2020-09-03 11:34:07 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.utils.tensorflow.models\u001b[0m  - Finished training.\n",
            "2020-09-03 11:34:07 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.agent\u001b[0m  - Persisted model to '/tmp/tmpgdn1wusu/core'\n",
            "\u001b[94mCore model training completed.\u001b[0m\n",
            "\u001b[94mTraining NLU model...\u001b[0m\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Training data stats:\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of intent examples: 43 (7 distinct intents)\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  -   Found intents: 'mood_unhappy', 'mood_great', 'goodbye', 'deny', 'bot_challenge', 'affirm', 'greet'\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of response examples: 0 (0 distinct responses)\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of entity examples: 0 (0 distinct entities)\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component RegexFeaturizer\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component LexicalSyntacticFeaturizer\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:08 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component DIETClassifier\n",
            "\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: You specified 'DIET' to train entities, but no entities are present in the training data. Skip training of entities.\n",
            "Epochs: 100% 100/100 [00:07<00:00, 13.00it/s, t_loss=1.470, i_loss=0.083, i_acc=1.000]\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.utils.tensorflow.models\u001b[0m  - Finished training.\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component EntitySynonymMapper\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component ResponseSelector\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.selectors.response_selector\u001b[0m  - Retrieval intent parameter was left to its default value. This response selector will be trained on training examples combining all retrieval intents.\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:34:23 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Successfully saved model into '/tmp/tmpgdn1wusu/nlu'\n",
            "\u001b[94mNLU model training completed.\u001b[0m\n",
            "\u001b[92mYour Rasa model is trained and saved at '/content/rasa/models/20200903-113337.tar.gz'.\u001b[0m\n",
            "If you want to speak to the assistant, run 'rasa shell' at any time inside the project directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRix1O4ixLC6",
        "colab_type": "text"
      },
      "source": [
        "* Training data\n",
        "\n",
        "I copy my training data in the file `rasa/data/nlu.md` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qyyTJRpxYk-",
        "colab_type": "text"
      },
      "source": [
        "* Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Bf7W0EgmtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b939c06-7ed1-4b2e-cd15-5d378cf9ddd2"
      },
      "source": [
        "!rasa train nlu"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[94mTraining NLU model...\u001b[0m\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Training data stats:\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of intent examples: 294 (3 distinct intents)\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  -   Found intents: 'agreement_title', 'agreement_parties', 'other_agreement_text'\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of response examples: 0 (0 distinct responses)\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  - Number of entity examples: 218 (14 distinct entities)\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.training_data.training_data\u001b[0m  -   Found entity types: 'agreement_date_label', 'agreement_label', 'agreement_date', 'party2_label', 'agreement_type', 'party2_address', 'party2_regcountry', 'party1', 'party1_regcountry', 'party2_number', 'party1_label', 'party1_address', 'party1_number', 'party2'\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component RegexFeaturizer\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:42:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component LexicalSyntacticFeaturizer\n",
            "2020-09-03 11:42:48 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:42:48 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
            "2020-09-03 11:42:48 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:42:48 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
            "2020-09-03 11:42:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Finished training component.\n",
            "2020-09-03 11:42:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.model\u001b[0m  - Starting to train component DIETClassifier\n",
            "\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: Misaligned entity annotation in message 'The Open University HIGHSKILLZ and THE OPEN UNIVERSITY VARIATION AGREEMENT The Open University Walton Hall Milton Keynes MK7 6AA CLS ref CLS-2947-03 Variation Agreement To Highskillz Collaboration Agreement (CLS-2947-01) Page 1 of 3 THIS VARIATION AGREEMENT is made the day of 2017 BETWEEN: 1 HIGHSKILLZ incorporated and registered in England and Wales (8072861) whose registered office is at 27 Wessex Gardens, NW11 9RS, United Kingdom ( \"HighSkillz\"); and 2 THE OPEN UNIVERSITY a body incorporated by Royal Charter (number RC 0003971), with charitable status in England and Wales, registered as a charity in Scotland (No. SC038302); and with its address at Walton Hall, Milton Keynes, Buckinghamshire, MK7 6AA, (\"the OU\"): (each a â€œPartyâ€ and together referred to as the â€œPartiesâ€) BACKGROUND (A) The Parties entered into an Agreement executed on the 24 December 2015 (the â€œAgreement\").' with intent 'agreement_parties'. Make sure the start and end values of entities in the training data match the token boundaries (e.g. entities don't include trailing whitespaces or punctuation).\n",
            "  More info at https://rasa.com/docs/rasa/nlu/training-data-format/\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: Misaligned entity annotation in message 'DataSpartan Consulting LTD and 2-sec Ltd Consultancy agreement 1 of 18 This Agreement is made on 2011.01.23 between: (i) DataSpartan Consulting LTD whose address is: 241, Royapettah High Rd, Azad Nagar, Royapettah, Chennai, Tamil Nadu 600014, India, company registration 99900099 (hereinafter â€œthe Consultantâ€) and (11) 2-sec Ltd whose registered office is at 5th Floor, Tower 42, 25 Old Broad Street, London EC2N 1HN (hereinafter â€œ2- secâ€).' with intent 'agreement_parties'. Make sure the start and end values of entities in the training data match the token boundaries (e.g. entities don't include trailing whitespaces or punctuation).\n",
            "  More info at https://rasa.com/docs/rasa/nlu/training-data-format/\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: Misaligned entity annotation in message 'COOK SPACE Equioment Rental Agreement This Equipment Rental Agreement (â€œAgreementâ€) is effective as of the date of first payment (â€œEffective Dateâ€), and is made between Mette Ltd, a Limited Company governed under the laws of England and Wales, with offices at 46 Hill Street, Belfast, Northern Ireland, BT1 2LB, and Glove Factory Studios, Brook Lane, Holt, Wiltshire BA14 6RL (â€œOwnerâ€), and Strong Roots (Handy Food Innovation Ltd), with offices at The Root System, Fourth Floor, 25-26 Earlsfort Terrace, Dublin 2, Ireland and 2 Stephen Street, London, W1T 1AN, UK (â€œRenterâ€). Owner and Renter are hereinafter collectively referred to as â€œPartiesâ€.' with intent 'agreement_parties'. Make sure the start and end values of entities in the training data match the token boundaries (e.g. entities don't include trailing whitespaces or punctuation).\n",
            "  More info at https://rasa.com/docs/rasa/nlu/training-data-format/\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: Misaligned entity annotation in message 'SOFTWARE DEVELOPMENT NON-DISCLOSURE AGREEMENT I. THE PARTIES. This Software Development Non-Disclosure Agreement, hereinafter known as the â€œAgreementâ€, created on the 9th day of May, 2015 is by and between Curnocopia PLC, hereinafter known as the â€œ1st Partyâ€, and Theo Goes To Ltd, hereinafter known as the â€œ2nd Partyâ€, and collectively known as the â€œPartiesâ€.' with intent 'agreement_parties'. Make sure the start and end values of entities in the training data match the token boundaries (e.g. entities don't include trailing whitespaces or punctuation).\n",
            "  More info at https://rasa.com/docs/rasa/nlu/training-data-format/\n",
            "Epochs:  29% 29/100 [02:47<07:05,  5.99s/it, t_loss=15.402, i_loss=0.085, entity_loss=11.359, i_acc=0.997, entity_f1=0.647]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/rasa\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/__main__.py\", line 92, in main\n",
            "    cmdline_arguments.func(cmdline_arguments)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/cli/train.py\", line 140, in train_nlu\n",
            "    persist_nlu_training_data=args.persist_nlu_data,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/train.py\", line 414, in train_nlu\n",
            "    persist_nlu_training_data,\n",
            "  File \"uvloop/loop.pyx\", line 1456, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/train.py\", line 453, in _train_nlu_async\n",
            "    persist_nlu_training_data=persist_nlu_training_data,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/train.py\", line 482, in _train_nlu_with_validated_data\n",
            "    persist_nlu_training_data=persist_nlu_training_data,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/nlu/train.py\", line 90, in train\n",
            "    interpreter = trainer.train(training_data, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/nlu/model.py\", line 191, in train\n",
            "    updates = component.train(working_data, self.config, **context)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/nlu/classifiers/diet_classifier.py\", line 723, in train\n",
            "    self.component_config[BATCH_STRATEGY],\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\", line 153, in fit\n",
            "    self.train_summary_writer,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\", line 303, in _batch_loop\n",
            "    call_model_function(batch_in)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 599, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 545, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[120,790,57] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[{{node If/else/_179/gradients/concat_grad/Slice_1}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            " [Op:__inference_train_on_batch_10919]\n",
            "\n",
            "Function call stack:\n",
            "train_on_batch\n",
            "\n",
            "Epochs:  29% 29/100 [03:02<07:25,  6.28s/it, t_loss=15.402, i_loss=0.085, entity_loss=11.359, i_acc=0.997, entity_f1=0.647]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HB_X0fztfZK",
        "colab_type": "text"
      },
      "source": [
        "## Train rasa_nlu by python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_px22Q81TIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf1fd130-4064-4a12-e30c-b48e956c878a"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roD9fGF5Yx-y",
        "colab_type": "text"
      },
      "source": [
        "* Install rasa (last version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVhkTwa5XN9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rasa\n",
        "!pip install rasa[convert]\n",
        "clear_output()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoBKYfdRBaKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install 'gast==0.2.2'\n",
        "clear_output()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc_cLD_bY1ou",
        "colab_type": "text"
      },
      "source": [
        "* Install spacy as pre-trained language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmYn1w6HXSDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy link en_core_web_md en --force\n",
        "clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc4WIyEJz7wB",
        "colab_type": "text"
      },
      "source": [
        "## Training data\n",
        "\n",
        "I upload my training data in the root folder in a file called `nlu_nda.md`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2hr_4ZDY8ge",
        "colab_type": "text"
      },
      "source": [
        "### Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgcW2OQYxWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rasa.nlu.model import Trainer\n",
        "from rasa.nlu import config\n",
        "from rasa.nlu.training_data import load_data\n",
        "from rasa.nlu.test import run_evaluation"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsdWUbbPZNne",
        "colab_type": "text"
      },
      "source": [
        "#### Interpreter 1: based in ConveRT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4w3PvC1ZV6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convertRT_pipeline = \"\"\"\n",
        "language: \"en\"\n",
        "\n",
        "pipeline:\n",
        "  - name: ConveRTTokenizer\n",
        "  - name: ConveRTFeaturizer\n",
        "  - name: RegexFeaturizer\n",
        "  - name: LexicalSyntacticFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "    analyzer: \"char_wb\"\n",
        "    min_ngram: 1\n",
        "    max_ngram: 4\n",
        "  - name: DIETClassifier\n",
        "    epochs: 100\n",
        "  - name: EntitySynonymMapper\n",
        "\"\"\"\n",
        "\n",
        "convertRT_pipeline_filepath = \"convertRT_pipeline.yml\"\n",
        "f = open(convertRT_pipeline_filepath, \"w\")\n",
        "f.write(convertRT_pipeline)\n",
        "f.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOs_xaRXfAHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "configuration = config.load(convertRT_pipeline_filepath)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeGZ-fuZYMLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "3ee87329-5ccc-4193-ab55-8000e9cc9ece"
      },
      "source": [
        "interpreter1 = Trainer(configuration)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERyV6YWdZf6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "ec55f104-b8bb-45b4-cf22-43c8f7b2dbce"
      },
      "source": [
        "training_nda_data_filepath = \"nlu_nda.md\"\n",
        "training_data = load_data(training_nda_data_filepath)\n",
        "interpreter1.train(training_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13<00:00,  2.71s/it]\n",
            "Response batches: 0it [00:00, ?it/s]\n",
            "\u001b[93m/usr/local/lib/python3.6/dist-packages/rasa/utils/common.py:363: UserWarning: Misaligned entity annotation in message 'COOK SPACE Equioment Rental Agreement This Equipment Rental Agreement (â€œAgreementâ€) is effective as of the date of first payment (â€œEffective Dateâ€), and is made between Mette Ltd, a Limited Company governed under the laws of England and Wales, with offices at 46 Hill Street, Belfast, Northern Ireland, BT1 2LB, and Glove Factory Studios, Brook Lane, Holt, Wiltshire BA14 6RL (â€œOwnerâ€), and Strong Roots (Handy Food Innovation Ltd), with offices at The Root System, Fourth Floor, 25-26 Earlsfort Terrace, Dublin 2, Ireland and 2 Stephen Street, London, W1T 1AN, UK (â€œRenterâ€). Owner and Renter are hereinafter collectively referred to as â€œPartiesâ€.' with intent 'agreement_parties'. Make sure the start and end values of entities in the training data match the token boundaries (e.g. entities don't include trailing whitespaces or punctuation).\n",
            "  More info at https://rasa.com/docs/rasa/nlu/training-data-format/\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e87c3c65f1d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_nda_data_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nlu_nda.md\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_nda_data_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minterpreter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/nlu/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting to train component {component.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_partial_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training component.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/nlu/classifiers/diet_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, config, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEVAL_NUM_EXAMPLES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEVAL_NUM_EPOCHS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_STRATEGY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model_data, epochs, batch_size, evaluate_on_num_examples, evaluate_every_num_epochs, batch_strategy, silent, loading, eager)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\u001b[0m in \u001b[0;36m_batch_loop\u001b[0;34m(self, dataset_function, call_model_function, batch_size, training, offset, writer)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m  \u001b[0;31m# needed for eager mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_in\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mcall_model_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_log_on_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[64,4,1527,1527] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node text_encoder/transformer_encoder_layer/multi_head_attention/Softmax (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:307) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[dot_product_loss/while/body/_1/range/_272]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[64,4,1527,1527] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node text_encoder/transformer_encoder_layer/multi_head_attention/Softmax (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:307) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_on_batch_75427]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node text_encoder/transformer_encoder_layer/multi_head_attention/Softmax:\n text_encoder/transformer_encoder_layer/multi_head_attention/add (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:299)\n\nInput Source operations connected to node text_encoder/transformer_encoder_layer/multi_head_attention/Softmax:\n text_encoder/transformer_encoder_layer/multi_head_attention/add (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:299)\n\nFunction call stack:\ntrain_on_batch -> train_on_batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoViBNQopic5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter1.persist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pmJEMFpcEyRs"
      },
      "source": [
        "#### Interpreter 2: based in Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wb15s6nGEyR1",
        "colab": {}
      },
      "source": [
        "spacy_pipeline = \"\"\"\n",
        "language: \"en\"\n",
        "\n",
        "pipeline:\n",
        "  - name: SpacyNLP\n",
        "  - name: SpacyTokenizer\n",
        "  - name: SpacyFeaturizer\n",
        "  - name: RegexFeaturizer\n",
        "  - name: LexicalSyntacticFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "    analyzer: \"char_wb\"\n",
        "    min_ngram: 1\n",
        "    max_ngram: 4\n",
        "  - name: DIETClassifier\n",
        "    epochs: 10\n",
        "  - name: EntitySynonymMapper\n",
        "\"\"\"\n",
        "\n",
        "spacy_pipeline_filepath = \"spacy_pipeline.yml\"\n",
        "f = open(spacy_pipeline_filepath, \"w\")\n",
        "f.write(spacy_pipeline)\n",
        "f.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G34iymXnEyR9",
        "colab": {}
      },
      "source": [
        "configuration = config.load(spacy_pipeline_filepath)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_OqifFdEySC",
        "colab": {}
      },
      "source": [
        "interpreter2 = Trainer(configuration)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOTLTR0XeYqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "2ac2e790-a8c3-4141-8b72-0bea4d7924be"
      },
      "source": [
        "training_nda_data_filepath = \"nlu_nda.md\"\n",
        "training_data = load_data(training_nda_data_filepath)\n",
        "interpreter2.train(training_data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Epochs:   0%|          | 0/10 [00:08<?, ?it/s, t_loss=142.266, i_loss=6.551, entity_loss=133.962, i_acc=0.503, entity_f1=0.015]\u001b[A\n",
            "Epochs:  10%|â–ˆ         | 1/10 [00:08<01:17,  8.64s/it, t_loss=142.266, i_loss=6.551, entity_loss=133.962, i_acc=0.503, entity_f1=0.015]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bcdfd195e216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_nda_data_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nlu_nda.md\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_nda_data_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minterpreter2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/nlu/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting to train component {component.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_partial_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training component.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/nlu/classifiers/diet_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, config, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEVAL_NUM_EXAMPLES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEVAL_NUM_EPOCHS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_STRATEGY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model_data, epochs, batch_size, evaluate_on_num_examples, evaluate_every_num_epochs, batch_strategy, silent, loading, eager)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/models.py\u001b[0m in \u001b[0;36m_batch_loop\u001b[0;34m(self, dataset_function, call_model_function, batch_size, training, offset, writer)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m  \u001b[0;31m# needed for eager mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_in\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mcall_model_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_log_on_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[85,4,1046,1046] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node text_encoder/transformer_encoder_layer_3/multi_head_attention_3/Softmax (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:307) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[dot_product_loss_1/while/body/_1/range/_272]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[85,4,1046,1046] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node text_encoder/transformer_encoder_layer_3/multi_head_attention_3/Softmax (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:307) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_on_batch_86375]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node text_encoder/transformer_encoder_layer_3/multi_head_attention_3/Softmax:\n text_encoder/transformer_encoder_layer_3/multi_head_attention_3/add (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:299)\n\nInput Source operations connected to node text_encoder/transformer_encoder_layer_3/multi_head_attention_3/Softmax:\n text_encoder/transformer_encoder_layer_3/multi_head_attention_3/add (defined at /usr/local/lib/python3.6/dist-packages/rasa/utils/tensorflow/transformer.py:299)\n\nFunction call stack:\ntrain_on_batch -> train_on_batch\n"
          ]
        }
      ]
    }
  ]
}