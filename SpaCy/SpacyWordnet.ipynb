{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpacyWordnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/SpacyWordnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ZDuAW7Eprc",
        "colab_type": "text"
      },
      "source": [
        "# SpaCy Wordnet\n",
        "\n",
        "WordNet provides a lexical database for English – in other words, it's a computable thesaurus.\n",
        "\n",
        "There's a spaCy integration for WordNet called spacy-wordnet by Daniel Vila Suero, an expert in natural language and knowledge graph work.\n",
        "\n",
        "GitHub: https://github.com/recognai/spacy-wordnet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBke4gRlFfQh",
        "colab_type": "text"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5bnBj3d6lBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c1da38e5-48f5-4d35-80eb-eb23c34a373c"
      },
      "source": [
        "!pip install spacy-wordnet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy-wordnet in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: nltk<3.4,>=3.3 in /usr/local/lib/python3.6/dist-packages (from spacy-wordnet) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<3.4,>=3.3->spacy-wordnet) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Q77pC1FhyC",
        "colab_type": "text"
      },
      "source": [
        "We download the thesaurus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7-0SLjZyQ-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f6b5ec6d-c05d-4fe1-e981-53514d20a23f"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lH_F0eRF19X",
        "colab_type": "text"
      },
      "source": [
        "We download the spacy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AItQThHoF2Gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "17432986-6626-47af-fe9c-d4acd58759de"
      },
      "source": [
        "! python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeE9t2SlFnRE",
        "colab_type": "text"
      },
      "source": [
        "## Example of usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7JcS1Q_C8cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHkCADtF87G",
        "colab_type": "text"
      },
      "source": [
        "We add the Wordnet annotator as a component in the spaCy pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uem2HAjc6rN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0257cc9b-8c36-406a-e757-92e8d1740cc9"
      },
      "source": [
        "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
        "\n",
        "print(\"before\", nlp.pipe_names)\n",
        "\n",
        "if \"WordnetAnnotator\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(WordnetAnnotator(nlp.lang), after=\"tagger\")\n",
        "    \n",
        "print(\"after\", nlp.pipe_names)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before ['tagger', 'parser', 'ner']\n",
            "after ['tagger', 'WordnetAnnotator', 'parser', 'ner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPraajJZGGip",
        "colab_type": "text"
      },
      "source": [
        "Get a word synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGnZQ2vs_617",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "379b1177-c258-46ff-d116-8f6845b269ab"
      },
      "source": [
        "token = nlp(\"withdraw\")[0]\n",
        "token._.wordnet.synsets()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('withdraw.v.01'),\n",
              " Synset('retire.v.02'),\n",
              " Synset('disengage.v.01'),\n",
              " Synset('recall.v.07'),\n",
              " Synset('swallow.v.05'),\n",
              " Synset('seclude.v.01'),\n",
              " Synset('adjourn.v.02'),\n",
              " Synset('bow_out.v.02'),\n",
              " Synset('withdraw.v.09'),\n",
              " Synset('retire.v.08'),\n",
              " Synset('retreat.v.04'),\n",
              " Synset('remove.v.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67fVCC31GaRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "29d81529-a1a8-4561-d298-69ef94fbf803"
      },
      "source": [
        "for s in token._.wordnet.synsets():\n",
        "  print(s.lemma_names())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['withdraw', 'retreat', 'pull_away', 'draw_back', 'recede', 'pull_back', 'retire', 'move_back']\n",
            "['retire', 'withdraw']\n",
            "['disengage', 'withdraw']\n",
            "['recall', 'call_in', 'call_back', 'withdraw']\n",
            "['swallow', 'take_back', 'unsay', 'withdraw']\n",
            "['seclude', 'sequester', 'sequestrate', 'withdraw']\n",
            "['adjourn', 'withdraw', 'retire']\n",
            "['bow_out', 'withdraw']\n",
            "['withdraw', 'draw', 'take_out', 'draw_off']\n",
            "['retire', 'withdraw']\n",
            "['retreat', 'pull_back', 'back_out', 'back_away', 'crawfish', 'crawfish_out', \"pull_in_one's_horns\", 'withdraw']\n",
            "['remove', 'take', 'take_away', 'withdraw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP7hZJ5hH5t4",
        "colab_type": "text"
      },
      "source": [
        "Get lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODJB_pdv_8hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6380ba3f-07cc-46c5-999e-1320636c0f3a"
      },
      "source": [
        "token._.wordnet.lemmas()[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('withdraw.v.01.withdraw'),\n",
              " Lemma('withdraw.v.01.retreat'),\n",
              " Lemma('withdraw.v.01.pull_away'),\n",
              " Lemma('withdraw.v.01.draw_back'),\n",
              " Lemma('withdraw.v.01.recede'),\n",
              " Lemma('withdraw.v.01.pull_back'),\n",
              " Lemma('withdraw.v.01.retire'),\n",
              " Lemma('withdraw.v.01.move_back'),\n",
              " Lemma('retire.v.02.retire'),\n",
              " Lemma('retire.v.02.withdraw')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ro610jIKWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4c630148-655d-43f2-eb8c-9e159a478d2b"
      },
      "source": [
        "for s in token._.wordnet.lemmas()[0:10]:\n",
        "  print(s.name())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "withdraw\n",
            "retreat\n",
            "pull_away\n",
            "draw_back\n",
            "recede\n",
            "pull_back\n",
            "retire\n",
            "move_back\n",
            "retire\n",
            "withdraw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3PvNZMnIQ4p",
        "colab_type": "text"
      },
      "source": [
        "Domains of the Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SperbvgiA8E6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "542f25ad-300d-4293-ab34-9e5ed10cbe86"
      },
      "source": [
        "token._.wordnet.wordnet_domains()[0:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['astronomy',\n",
              " 'school',\n",
              " 'telegraphy',\n",
              " 'industry',\n",
              " 'psychology',\n",
              " 'ethnology',\n",
              " 'ethnology',\n",
              " 'administration',\n",
              " 'school',\n",
              " 'finance']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLPxJT7sIYLs",
        "colab_type": "text"
      },
      "source": [
        "### Example of applicability\n",
        "\n",
        "Complete a sentence with the word synonyms for a specific group of domains.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5ghgPt4BAys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ce51e54-4bda-4f9e-867d-67bdcbcb390a"
      },
      "source": [
        "domains = [\"finance\", \"banking\"]\n",
        "sentence = nlp(\"I want to withdraw 5,000 euros.\")\n",
        "\n",
        "enriched_sent = []\n",
        "\n",
        "for token in sentence:\n",
        "    # get synsets within the desired domains\n",
        "    synsets = token._.wordnet.wordnet_synsets_for_domain(domains)\n",
        "    \n",
        "    if synsets:\n",
        "        lemmas_for_synset = []\n",
        "        \n",
        "        for s in synsets:\n",
        "            # get synset variants and add to the enriched sentence\n",
        "            lemmas_for_synset.extend(s.lemma_names())\n",
        "            enriched_sent.append(\"({})\".format(\"|\".join(set(lemmas_for_synset))))\n",
        "    else:\n",
        "        enriched_sent.append(token.text)\n",
        "\n",
        "print(\" \".join(enriched_sent))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I (need|want|require) to (draw_off|take_out|draw|withdraw) 5,000 euros .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp0UEijtBIVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}