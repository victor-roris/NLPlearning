{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom pipelines and extensions for spaCy.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/Custom_pipelines_and_extensions_for_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM_74FCY9blI",
        "colab_type": "text"
      },
      "source": [
        "# Custom pipelines and extensions for spaCy\n",
        "\n",
        "This notebook includes the code of the blog entry in the spaCy blog: https://explosion.ai/blog/spacy-v2-pipelines-extensions\n",
        "\n",
        "Here we describe how customize pipelines and add extension in spaCy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y09ZuzGpSh_",
        "colab_type": "text"
      },
      "source": [
        "If it is the first time, you should install the spacy model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMIII3XPpHDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "52c6f8c2-f14d-428e-d61a-84fa373174f4"
      },
      "source": [
        "! python -m spacy download es_core_news_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: es_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz#egg=es_core_news_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTG9EWd2pc2T",
        "colab_type": "text"
      },
      "source": [
        "**Note**: after the installation, you should re-initialize the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj8IobK2orIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgbna8K4oti4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a spaCy model, depending on language, scale, etc.\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcloYOBmq-9s",
        "colab_type": "text"
      },
      "source": [
        "## Custom pipeline components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbczMJEPraMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b9bdd652-19a8-435a-9312-77cffc0c9223"
      },
      "source": [
        "print('Default PIPELINE components: ')\n",
        "nlp.pipeline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default PIPELINE components: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fcce0dcff60>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fcce0d4c9a8>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fcce0d4ca08>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipzL-pVxtoIJ",
        "colab_type": "text"
      },
      "source": [
        "At a minimum, a component needs to be a callable that takes a Doc and returns it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxpuofLIpQkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_component(doc):\n",
        "  print(\"The doc is {} characters long and has {} tokens.\".format(len(doc.text), len(doc)))\n",
        "  return doc\n",
        "\n",
        "def my_component2(doc):\n",
        "  print(\"The first word in the text is '{}'.\".format(doc[0]))\n",
        "  return doc\n",
        "\n",
        "def my_component3(doc):\n",
        "  print(\"This is a component executed after the pipe 'parser'\")\n",
        "  return doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHG0Sfe6rS_O",
        "colab_type": "text"
      },
      "source": [
        "The component can then be added at any position of the pipeline using the nlp.add_pipe() method. The arguments before, after, first, and last let you specify component names to insert the new component before or after, or tell spaCy to insert it first (i.e. directly after tokenization) or last in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWAgr_6TprJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "577f0608-2d32-499a-a533-e211aec53f62"
      },
      "source": [
        "#Add your components to the nlp pipeline in the order you want\n",
        "if 'print_length' not in nlp.pipe_names:\n",
        "  nlp.add_pipe(my_component, name='print_length', last=True)\n",
        "if 'print_first' not in nlp.pipe_names:\n",
        "  nlp.add_pipe(my_component2, name='print_first', first=True)\n",
        "if 'after_parser' not in nlp.pipe_names:\n",
        "  nlp.add_pipe(my_component3, name='after_parser', after='parser')\n",
        "\n",
        "print('New PIPELINE components: ')\n",
        "nlp.pipeline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New PIPELINE components: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('print_first', <function __main__.my_component2>),\n",
              " ('tagger', <spacy.pipeline.pipes.Tagger at 0x7fcce0dcff60>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fcce0d4c9a8>),\n",
              " ('after_parser', <function __main__.my_component3>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fcce0d4ca08>),\n",
              " ('print_length', <function __main__.my_component>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-yku6M1t1D9",
        "colab_type": "text"
      },
      "source": [
        "We test the components are callable during the spacy execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1T_t7Ztq2O0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "adbf8321-d642-449e-d419-2f5ec3a419bb"
      },
      "source": [
        "doc = nlp(u\"Esta es una frase.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first word in the text is 'Esta'.\n",
            "This is a component executed after the pipe 'parser'\n",
            "The doc is 18 characters long and has 5 tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFv0TtaqzEtj",
        "colab_type": "text"
      },
      "source": [
        "We remove the components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnxlT84ys_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b96f61be-055e-48a6-d552-6d981127752d"
      },
      "source": [
        "if 'print_length' in nlp.pipe_names:\n",
        "  nlp.remove_pipe('print_length')\n",
        "if 'print_first' in nlp.pipe_names:\n",
        "  nlp.remove_pipe('print_first')\n",
        "if 'after_parser' in nlp.pipe_names:\n",
        "  nlp.remove_pipe('after_parser')\n",
        "\n",
        "print('New PIPELINE components: ')\n",
        "nlp.pipeline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New PIPELINE components: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fcce0dcff60>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fcce0d4c9a8>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fcce0d4ca08>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ALbBSRFwxqR",
        "colab_type": "text"
      },
      "source": [
        "## Extension attributes on Doc, Token and Span"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfbKxaE6w_LS",
        "colab_type": "text"
      },
      "source": [
        "spaCy v2.0 introduces a new mechanism that lets you register your own attributes, properties and methods that become available in the ._ namespace, for example, doc._.my_attr. There are mostly three types of extensions that can be registered via the set_extension() method:\n",
        "\n",
        "\n",
        "1.   Attribute extensions. Set a default value for an attribute, which can be overwritten.\n",
        "2.   Property extensions. Define a getter and an optional setter function.\n",
        "3.   Method extensions. Assign a function that becomes available as an object method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo5BzXle3Axy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a6c05fad-acd8-45b7-ac57-ce875f508c06"
      },
      "source": [
        "from spacy.tokens import Doc\n",
        "\n",
        "def get_value(doc):\n",
        "  return 'value'\n",
        "\n",
        "def set_value(value):\n",
        "  print(f\"Set Value {value}\")\n",
        "\n",
        "Doc.set_extension('hello_attr', default=True, force=True)\n",
        "Doc.set_extension('hello_property', getter=get_value, setter=set_value, force=True)\n",
        "Doc.set_extension('hello_method', method=lambda doc, name: 'Hi {}!'.format(name), force=True)\n",
        "\n",
        "print(doc._.hello_attr)            # True\n",
        "print(doc._.hello_property)        # return value of get_value\n",
        "print(doc._.hello_method('Ines'))  # 'Hi Ines!'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "value\n",
            "Hi Ines!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBw1UkETzy8L",
        "colab_type": "text"
      },
      "source": [
        "The following example shows a simple pipeline component that fetches all countries using the REST Countries API, finds the country names in the document, merges the matched spans, assigns the entity label GPE (geopolitical entity) and adds the country's capital, latitude/longitude coordinates and a boolean is_country to the token attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHuyWeXPq5CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from spacy.tokens import Token, Span\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "class Countries(object):\n",
        "    name = 'countries'  # component name shown in pipeline\n",
        "\n",
        "    def __init__(self, nlp, label='GPE'):\n",
        "        # request all country data from the API\n",
        "        r = requests.get('https://restcountries.eu/rest/v2/all')\n",
        "        self.countries = {c['name']: c for c in r.json()}  # create dict for easy lookup\n",
        "        # initialise the matcher and add patterns for all country names\n",
        "        self.matcher = PhraseMatcher(nlp.vocab)\n",
        "        self.matcher.add('COUNTRIES', None, *[nlp(c) for c in self.countries.keys()])\n",
        "        self.label = nlp.vocab.strings[label] # get label ID from vocab\n",
        "        # register extensions on the Token\n",
        "        if not Token.has_extension('is_country'):\n",
        "          Token.set_extension('is_country', default=False)\n",
        "        if not Token.has_extension('country_capital'):\n",
        "          Token.set_extension('country_capital', default=\"\")\n",
        "        if not Token.has_extension('country_latlng'):\n",
        "          Token.set_extension('country_latlng', default=\"\")\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        matches = self.matcher(doc)\n",
        "        spans = []  # keep the spans for later so we can merge them afterwards\n",
        "        for _, start, end in matches:\n",
        "            # create Span for matched country and assign label\n",
        "            entity = Span(doc, start, end, label=self.label)\n",
        "            spans.append(entity)\n",
        "            for token in entity:  # set values of token attributes\n",
        "                token._.set('is_country', True)\n",
        "                token._.set('country_capital', self.countries[entity.text]['capital'])\n",
        "                token._.set('country_latlng', self.countries[entity.text]['latlng'])\n",
        "        doc.ents = list(doc.ents) + spans  # overwrite doc.ents and add entities – don't replace!\n",
        "        for span in spans:\n",
        "            span.merge()  # merge all spans at the end to avoid mismatched indices\n",
        "        return doc  # don't forget to return the Doc!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A5l6hhkx9Xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "fb324ad9-9397-4671-e29e-6bdc52469747"
      },
      "source": [
        "component = Countries(nlp)\n",
        "nlp.add_pipe(component, before='tagger')\n",
        "doc = nlp(u\"texto sobre Colombia y la Czech Republic\")\n",
        "\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "# [('Colombia', 'GPE'), ('Czech Republic', 'GPE')]\n",
        "\n",
        "print([(token.text, token._.country_capital) for token in doc if token._.is_country])\n",
        "# [('Colombia', 'Bogotá'), ('Czech Republic', 'Prague')]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0373f695993e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"texto sobre Colombia y la Czech Republic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6fe2c5906ede>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nlp, label)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# initialise the matcher and add patterns for all country names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraseMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COUNTRIES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get label ID from vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# register extensions on the Token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6fe2c5906ede>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# initialise the matcher and add patterns for all country names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraseMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COUNTRIES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get label ID from vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# register extensions on the Token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6fe2c5906ede>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'country_capital'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'capital'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'country_latlng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latlng'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspans\u001b[0m  \u001b[0;31m# overwrite doc.ents and add entities – don't replace!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge all spans at the end to avoid mismatched indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(0, 2, 'GPE')' and '(1, 2, 'GPE')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqJZkHea4iQG",
        "colab_type": "text"
      },
      "source": [
        "Using getters and setters, you can also implement attributes on the Doc and Span that reference custom Token attributes – for example, whether a document contains countries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxJ-7PHY0N0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "has_country = lambda tokens: any([token._.is_country for token in tokens])\n",
        "Doc.set_extension('has_country', getter=has_country)\n",
        "Span.set_extension('has_country', getter=has_country)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DREh2d6y4jGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e4e80383-6322-407c-dd11-8eca345af28b"
      },
      "source": [
        "print(doc)\n",
        "print(f' - Exist a country in the text = {doc._.has_country}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto sobre Colombia y la Czech Republic\n",
            "Exist a country in the text True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4WQHKb34xHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "10ff2f98-922d-4d20-b622-1d9f04961ee4"
      },
      "source": [
        "span_ = doc[0:3]\n",
        "print(span_)\n",
        "print(f' - Exist a country in the span = {span_._.has_country}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto sobre Colombia\n",
            " - Exist a country in the span = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1tfD5fx48wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "78e77562-ff6d-4ba8-95a0-738dc0a16a34"
      },
      "source": [
        "span_ = doc[0:2]\n",
        "print(span_)\n",
        "print(f' - Exist a country in the span = {span_._.has_country}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto sobre\n",
            " - Exist a country in the span = False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbNVeL-W9PYF",
        "colab_type": "text"
      },
      "source": [
        "## Example: Emoji handling with spacymoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UzMFkOr84zX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "8bb7da6c-0818-4826-f262-c7812e06ef67"
      },
      "source": [
        "! pip install spacymoji"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacymoji\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/42/b4460030eb06504451973609ab8a95b8c0106090aca7a4d657baf9b2611d/spacymoji-2.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.3 in /usr/local/lib/python3.6/dist-packages (from spacymoji) (2.1.9)\n",
            "Collecting emoji<1.0.0,>=0.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.9.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (1.17.4)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (0.2.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.3->spacymoji) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy<3.0.0,>=2.1.3->spacymoji) (4.28.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.3->spacymoji) (2.8)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=f7d5d5f374dcff11680af29f2d66a4258cbb47ea66ef32bdd8cb0669acecb623\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, spacymoji\n",
            "Successfully installed emoji-0.5.4 spacymoji-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBm0-eSm5RZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacymoji import Emoji\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "emoji = Emoji(nlp)\n",
        "nlp.add_pipe(emoji, first=True)\n",
        "\n",
        "doc  = nlp(u\"This is a test 😻 👍🏿\")\n",
        "assert doc._.has_emoji\n",
        "assert len(doc._.emoji) == 2\n",
        "assert doc[2:5]._.has_emoji\n",
        "assert doc[4]._.is_emoji\n",
        "assert doc[5]._.emoji_desc == u'thumbs up dark skin tone'\n",
        "assert doc._.emoji[1] == (u'👍🏿', 5, u'thumbs up dark skin tone')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPK8iev1815u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5736a404-ae30-4cf6-bc3c-e3d42cc52eb7"
      },
      "source": [
        "doc[4]._.emoji_desc"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'smiling cat face with heart-eyes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-n9Oy_l9MS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}