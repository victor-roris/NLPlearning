{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPModel_MultiLabel_XGBoost_TFIDFVectorization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/NLPModel_MultiLabel_XGBoost_TFIDFVectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAx0osp1c_h",
        "colab_type": "text"
      },
      "source": [
        "# NLP Model with XGBoost\n",
        "\n",
        "In this notebook we are going to train a XGBoost Model to predict categories of text. To vectorize the text we are going to use the TFIDF approach. \n",
        "\n",
        "XGBoost: https://xgboost.readthedocs.io/en/latest/\n",
        "\n",
        "Sklearn TFIDF: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "Notebook adapted from: https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kth0fn9nnyBW",
        "colab_type": "text"
      },
      "source": [
        "## Fetch data\n",
        "\n",
        "We use the sklearn direct dataset 20 news groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv_qGkzjcFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErEBZFLnJ8H",
        "colab_type": "code",
        "outputId": "b4714f36-7b12-4104-f070-7c0f8a854502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_raw_df = fetch_20newsgroups(subset='train')\n",
        "test_raw_df = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKvmU9pnSGL",
        "colab_type": "code",
        "outputId": "a17abb84-ea65-4faf-96ac-f1ee96d1e499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(f'Number of raw training examples: {len(train_raw_df.data)}')\n",
        "print(f'Number of raw test examples: {len(test_raw_df.data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of raw training examples: 11314\n",
            "Number of raw test examples: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcsI_yLoSio",
        "colab_type": "code",
        "outputId": "3f1b791d-1a52-4e9b-dadb-894632bcef33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "category_names = np.unique(np.array(train_raw_df.target_names))\n",
        "print(f'Number of different categories : {len(category_names)}')\n",
        "print(f'Category list: {category_names}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different categories : 20\n",
            "Category list: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQ_WAHane2l",
        "colab_type": "code",
        "outputId": "975d80d1-fe80-4f8d-d1e7-00ae39f2dac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "print('Example of entry:')\n",
        "print(f'\\t - LABEL : {train_raw_df.target[0]} - {train_raw_df.target_names[0]}')\n",
        "print(f'\\t - {train_raw_df.data[0]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of entry:\n",
            "\t - LABEL : 7 - alt.atheism\n",
            "\t - From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfRxZq_HpKrK",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ_wiaxHoFbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_raw_df.data\n",
        "y_train = train_raw_df.target\n",
        "\n",
        "x_test = test_raw_df.data\n",
        "y_test = test_raw_df.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_xK8v50qMq_",
        "colab_type": "text"
      },
      "source": [
        "## Model training\n",
        "\n",
        "We are going to use a model that doesn't use raw text as input. It use a vectorization of the text. For this, we are going to create a pipeline that allows combine the vectorizer and the model in the same structure.\n",
        "\n",
        "The vectorization is via TFIDF codification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43t_3fxkjlcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word Embedding via TFIDF - vectorization of the text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Pipeline execution to combine vectorization and model execution\n",
        "from sklearn.pipeline import make_pipeline \n",
        "\n",
        "# Definition of generic models\n",
        "from xgboost import XGBClassifier  # XGBoost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp2uU1qdjqY2",
        "colab_type": "code",
        "outputId": "668f6036-4df0-4a31-ce8e-6b3289a5f541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Train the vectorizer with the training documents to codify the text in a TFIDF representation \n",
        "vec = TfidfVectorizer()\n",
        "vec.fit(x_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkXPXAeP3hyb",
        "colab_type": "text"
      },
      "source": [
        "*XGBClassifier* : Implementation of the scikit-learn API for XGBoost classification.\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_api.html?highlight=xgbclassifier#xgboost.XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AxuWNrZjyIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "estimator = XGBClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Jh-PBMxSsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the pipeline with the vectorizer and the model\n",
        "pipeline = make_pipeline(vec, estimator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhMA8xkKxU5x",
        "colab_type": "code",
        "outputId": "aeae90ae-d202-40a6-98d5-e276ac84da6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "# Train in the model\n",
        "pipeline.fit(x_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwP-RiEswyxZ",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkg1ypWjkOd7",
        "colab_type": "code",
        "outputId": "801d43b8-c848-4c79-f024-58d03a61c336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = pipeline.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.62      0.68       319\n",
            "           1       0.65      0.70      0.67       389\n",
            "           2       0.70      0.71      0.71       394\n",
            "           3       0.61      0.69      0.65       392\n",
            "           4       0.76      0.77      0.76       385\n",
            "           5       0.78      0.64      0.71       395\n",
            "           6       0.75      0.86      0.80       390\n",
            "           7       0.85      0.74      0.79       396\n",
            "           8       0.88      0.85      0.87       398\n",
            "           9       0.82      0.85      0.83       397\n",
            "          10       0.89      0.86      0.88       399\n",
            "          11       0.88      0.80      0.84       396\n",
            "          12       0.42      0.60      0.49       393\n",
            "          13       0.84      0.72      0.78       396\n",
            "          14       0.83      0.84      0.83       394\n",
            "          15       0.81      0.89      0.85       398\n",
            "          16       0.63      0.77      0.69       364\n",
            "          17       0.96      0.72      0.83       376\n",
            "          18       0.60      0.52      0.56       310\n",
            "          19       0.61      0.53      0.57       251\n",
            "\n",
            "    accuracy                           0.74      7532\n",
            "   macro avg       0.75      0.73      0.74      7532\n",
            "weighted avg       0.76      0.74      0.75      7532\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWm5goHF3TQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}