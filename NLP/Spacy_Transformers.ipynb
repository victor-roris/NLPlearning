{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_Transformers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/Spacy_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBYCwlzp9ZF2",
        "colab_type": "text"
      },
      "source": [
        "# Spacy meets Transformers\n",
        "\n",
        "https://explosion.ai/blog/spacy-transformers\n",
        "\n",
        "Spacy includes a new interface library to connect spaCy with Hugging Face transformers implementation.\n",
        "\n",
        "This library includes new components in the spacy pipeline:\n",
        " - **trf_wordpiecer**: model's wordpiece pre-processing (bert or xlnet, ex. 'encode' : 'en', '##code')\n",
        " - **trf_tok2vec**: runs the transformer over the doc, and saves the results into the built-in `doc.tensor` attribute and several extension attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFhNNW5Z9yPp",
        "colab_type": "text"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIrsZo6Y4TMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51ce516f-fc35-4aa8-9d0d-a8c209edde7e"
      },
      "source": [
        "! pip install spacy-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/fb/5dbcf7391d6ba0003fb922737340bff5033729f9c967f08f0468259c4f6a/spacy-transformers-0.5.1.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hCollecting spacy<2.3.0,>=2.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 13.9MB/s \n",
            "\u001b[?25hCollecting transformers<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/99/ca0e4c35ccde7d290de3c9c236d5629d1879b04927e5ace9bd6d9183e236/transformers-2.0.0-py3-none-any.whl (290kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (1.3.1)\n",
            "Collecting torchcontrib<0.1.0,>=0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (0.2.0)\n",
            "Collecting ftfy<6.0.0,>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hCollecting dataclasses<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: importlib_metadata>=0.20 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (0.23)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (41.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (2.21.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.17.4)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/d5/46ff975f0d7d055cf95557b944fd5d29d9dfb37a4341038e070f212b24fe/catalogue-0.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (2.0.3)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 38.5MB/s \n",
            "\u001b[?25hCollecting blis<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 41.8MB/s \n",
            "\u001b[?25hCollecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 37.8MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (4.28.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (1.10.18)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers) (0.1.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib_metadata>=0.20->spacy-transformers) (0.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.13.18)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.14.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib_metadata>=0.20->spacy-transformers) (7.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (2.6.1)\n",
            "Building wheels for collected packages: spacy-transformers, torchcontrib, ftfy, sacremoses\n",
            "  Building wheel for spacy-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-transformers: filename=spacy_transformers-0.5.1-py2.py3-none-any.whl size=52837 sha256=46ae2f8ec2d33bbc1847ce443d4957bed179898215c288bce9abcb556a46f50f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/c2/17/625a3d14da8cabe9781ab1648d489d1b41a8a81dc289e5af1f\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7530 sha256=bd2d8014ad84cbfa73547cc5ed98463dcbf54cb32f4620f48dabed7f717aebd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=fd1573deb55734dd73db660731097a925852991263290741a2d994dd80d1917e\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=9d494858986a75684b00bbc2a038b2a273483be48e90c48b8c9abfa251c2936c\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built spacy-transformers torchcontrib ftfy sacremoses\n",
            "Installing collected packages: catalogue, preshed, blis, thinc, spacy, regex, sentencepiece, sacremoses, transformers, torchcontrib, ftfy, dataclasses, spacy-transformers\n",
            "  Found existing installation: preshed 2.0.1\n",
            "    Uninstalling preshed-2.0.1:\n",
            "      Successfully uninstalled preshed-2.0.1\n",
            "  Found existing installation: blis 0.2.4\n",
            "    Uninstalling blis-0.2.4:\n",
            "      Successfully uninstalled blis-0.2.4\n",
            "  Found existing installation: thinc 7.0.8\n",
            "    Uninstalling thinc-7.0.8:\n",
            "      Successfully uninstalled thinc-7.0.8\n",
            "  Found existing installation: spacy 2.1.9\n",
            "    Uninstalling spacy-2.1.9:\n",
            "      Successfully uninstalled spacy-2.1.9\n",
            "  Found existing installation: dataclasses 0.7\n",
            "    Uninstalling dataclasses-0.7:\n",
            "      Successfully uninstalled dataclasses-0.7\n",
            "Successfully installed blis-0.4.1 catalogue-0.0.8 dataclasses-0.6 ftfy-5.6 preshed-3.0.2 regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 spacy-2.2.3 spacy-transformers-0.5.1 thinc-7.3.1 torchcontrib-0.0.2 transformers-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug7r79br4Un_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "9c8578bb-e907-488c-9575-4e825c521e91"
      },
      "source": [
        "! python -m spacy download en_trf_bertbaseuncased_lg\n",
        "! python -m spacy download en_trf_xlnetbasecased_lg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_trf_bertbaseuncased_lg==2.2.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_trf_bertbaseuncased_lg-2.2.0/en_trf_bertbaseuncased_lg-2.2.0.tar.gz (405.8MB)\n",
            "\u001b[K     |████████████████████████████████| 405.8MB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from en_trf_bertbaseuncased_lg==2.2.0) (2.2.3)\n",
            "Requirement already satisfied: spacy-transformers>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from en_trf_bertbaseuncased_lg==2.2.0) (0.5.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (41.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (0.9.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (2.21.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (0.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (0.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (1.17.4)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (7.3.1)\n",
            "Requirement already satisfied: transformers<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (2.0.0)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.6)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (5.6)\n",
            "Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.23)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (2019.9.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.1->en_trf_bertbaseuncased_lg==2.2.0) (4.28.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.0.35)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (1.10.18)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.1.83)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (2019.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.1.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (7.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (1.13.18)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.9.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (7.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_bertbaseuncased_lg==2.2.0) (2.6.1)\n",
            "Building wheels for collected packages: en-trf-bertbaseuncased-lg\n",
            "  Building wheel for en-trf-bertbaseuncased-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-trf-bertbaseuncased-lg: filename=en_trf_bertbaseuncased_lg-2.2.0-cp36-none-any.whl size=405819945 sha256=59f61c92d68f3bbd23d333e6f211cd12a2797c7fce48a607d7715df0e924c7f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zr0h2sfa/wheels/f6/60/8c/c6f517ef9729972f1be15c3aab4b93e7ec9fbeb71d072a84de\n",
            "Successfully built en-trf-bertbaseuncased-lg\n",
            "Installing collected packages: en-trf-bertbaseuncased-lg\n",
            "Successfully installed en-trf-bertbaseuncased-lg-2.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_trf_bertbaseuncased_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW4LR7w3Ajl_",
        "colab_type": "text"
      },
      "source": [
        "Restart the environment after the model was downloaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJTELRoYAwYo",
        "colab_type": "text"
      },
      "source": [
        "## Basic introduction example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufraShe-4imo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "0dc83a82-7251-4107-dec7-3f50fd29bddb"
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "import numpy\n",
        "from numpy.testing import assert_almost_equal\n",
        "\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
        "\n",
        "text = \"Here is some text to encode.\"\n",
        "doc = nlp(text)\n",
        "print(f'Text to analyse: \"{text}\" \\n')\n",
        "\n",
        "print(f'Tokens in the text ({len(doc)}):')\n",
        "for token in doc:\n",
        "  print(f'\\t{token.text}')\n",
        "print()\n",
        "\n",
        "assert doc.tensor.shape == (7, 768)  # Always has one row per token\n",
        "print(f'spaCy doc tensor with a row per text token : {doc.tensor.shape} \\n')\n",
        "\n",
        "\n",
        "print('spaCy transformers attributes : ')\n",
        "print(f'\\t - String values of the wordpieces:')  \n",
        "print(f'\\t\\t > doc._.trf_word_pieces_ = {doc._.trf_word_pieces_}')  # String values of the wordpieces\n",
        "print(f'\\t - Wordpiece IDs (note: *not* spaCy`s hash values!):')  \n",
        "print(f'\\t\\t > doc._.trf_word_pieces = {doc._.trf_word_pieces}')  # Wordpiece IDs (note: *not* spaCy's hash values!)\n",
        "print(f'\\t - Alignment between spaCy tokens and wordpieces:')  \n",
        "print(f'\\t\\t > doc._.trf_alignment = {doc._.trf_alignment}')  # Alignment between spaCy tokens and wordpieces\n",
        "print()\n",
        "\n",
        "# The raw transformer output has one row per wordpiece.\n",
        "assert len(doc._.trf_last_hidden_state) == len(doc._.trf_word_pieces)\n",
        "print(f'doc._.trf_outputs.last_hidden_state - gives you a tensor with one row per wordpiece token. {doc._.trf_last_hidden_state.shape}')\n",
        "print()\n",
        "\n",
        "# To avoid losing information, we calculate the doc.tensor attribute such that\n",
        "# the sum-pooled vectors match (apart from numeric error)\n",
        "assert_almost_equal(doc.tensor.sum(axis=0), doc._.trf_last_hidden_state.sum(axis=0), decimal=5)\n",
        "print(\"The sum-pooled vector from the 'doc.tensor' and the 'trf_last_hidden_state' are practically equals \")\n",
        "print(f'\\t > sum(doc.tensor.sum(axis=0)) = {sum(doc.tensor.sum(axis=0))}')\n",
        "print(f'\\t > sum(doc._.trf_last_hidden_state.sum(axis=0)) = {sum(doc._.trf_last_hidden_state.sum(axis=0))}')\n",
        "print()\n",
        "\n",
        "# Access the tensor from Span elements (especially helpful for sentences)\n",
        "span = doc[2:4]\n",
        "assert numpy.array_equal(span.tensor, doc.tensor[2:4])\n",
        "print('Is the same access to a span tensor than the doc tensor limit to the span')\n",
        "print(f'- Span = doc[2:4] : {span}')\n",
        "print(f'- span.tensor : {span.tensor}')\n",
        "print(f'- doc.tensor[2:4] : {doc.tensor[2:4]}')\n",
        "print()\n",
        "\n",
        "\n",
        "# .vector and .similarity use the transformer outputs\n",
        "apple1 = nlp(\"Apple shares rose on the news.\")\n",
        "apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
        "apple3 = nlp(\"Apple pie is delicious.\")\n",
        "print('WORD SIMILARITY:')\n",
        "print(apple1[0].similarity(apple2[0]))  # 0.73428553\n",
        "print(apple1[0].similarity(apple3[0]))  # 0.43365782"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to analyse: \"Here is some text to encode.\" \n",
            "\n",
            "Tokens in the text (7):\n",
            "\tHere\n",
            "\tis\n",
            "\tsome\n",
            "\ttext\n",
            "\tto\n",
            "\tencode\n",
            "\t.\n",
            "\n",
            "spaCy doc tensor with a row per text token : (7, 768) \n",
            "\n",
            "spaCy transformers attributes : \n",
            "\t - String values of the wordpieces:\n",
            "\t\t > doc._.trf_word_pieces_ = ['[CLS]', 'here', 'is', 'some', 'text', 'to', 'en', '##code', '.', '[SEP]']\n",
            "\t - Wordpiece IDs (note: *not* spaCy`s hash values!):\n",
            "\t\t > doc._.trf_word_pieces = [101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 1012, 102]\n",
            "\t - Alignment between spaCy tokens and wordpieces:\n",
            "\t\t > doc._.trf_alignment = [[1], [2], [3], [4], [5], [6, 7], [8]]\n",
            "\n",
            "doc._.trf_outputs.last_hidden_state - gives you a tensor with one row per wordpiece token. (10, 768)\n",
            "\n",
            "The sum-pooled vector from the 'doc.tensor' and the 'trf_last_hidden_state' are practically equals \n",
            "\t > sum(doc.tensor.sum(axis=0)) = -99.45763402432203\n",
            "\t > sum(doc._.trf_last_hidden_state.sum(axis=0)) = -99.45762564986944\n",
            "\n",
            "Is the same access to a span tensor than the doc tensor limit to the span\n",
            "- Span = doc[2:4] : some text\n",
            "- span.tensor : [[ 0.07593206 -0.45352632  0.24927768 ...  0.28133267 -0.45936888\n",
            "   0.83061326]\n",
            " [ 0.19304001  0.3288497   0.38221556 ... -0.24274416 -0.18937224\n",
            "   0.5018022 ]]\n",
            "- doc.tensor[2:4] : [[ 0.07593206 -0.45352632  0.24927768 ...  0.28133267 -0.45936888\n",
            "   0.83061326]\n",
            " [ 0.19304001  0.3288497   0.38221556 ... -0.24274416 -0.18937224\n",
            "   0.5018022 ]]\n",
            "\n",
            "WORD SIMILARITY:\n",
            "0.73428494\n",
            "0.43365708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8AMBZzfHIXg",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning\n",
        "\n",
        "For a more advanced example: https://github.com/explosion/spacy-transformers/blob/master/examples/train_textcat.py\n",
        "\n",
        "You load in a large generic model pretrained on lots of text, and start training on your smaller dataset with labels specific to your problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDEAwq4IaT0A",
        "colab_type": "text"
      },
      "source": [
        "I use definitions of cat and definitions of Boris Jonhson to train the model (note, I use `cat` because I was a bit conditioned by the `cats` key. But now I think this was a bad decision. Because a external reader can think the key `cats` is related with the text definitions and don't. The key `cats` in the sencond entry of the tuple is related with *categories*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0il2HM7w6DXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = [\n",
        "    # CAT\n",
        "    (\"a small domesticated carnivorous mammal with soft fur, a short snout, and retractable claws. It is widely kept as a pet or for catching mice, and many breeds have been developed.\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "    (\"a small animal with fur, four legs, a tail, and claws, usually kept as a pet or for catching mice\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "    (\"a small, furry animal with four legs and a tail, often kept as a pet, or any of a group of related animals that are wild, and some of which are large and fierce, such as the lion\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "    (\"a carnivorous mammal (Felis catus) long domesticated as a pet and for catching rats and mice.\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "    (\"a small domesticated carnivore, Felis domestica or F. catus, bred in a number of varieties\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "    (\"a furry animal that has a long tail and sharp claws. Cats are often kept as pets.\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0}}),\n",
        "\n",
        "    # No-CAT (Alexander Boris de Pfeffel Johnson Hon FRIBA)\n",
        "    (\"is a British politician, writer, and former journalist who has served as Prime Minister of the United Kingdom \", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"is a leading Conservative politician, who was elected leader of the Conservative Party in the summer of 2019, becoming Prime Minister\", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"is a British politician, popular historian, and journalist who is Prime Minister of the United Kingdom \", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"Born in New York City on June 19, 1964 to British parents, Johnson spent his first five years in Manhattan while his father was studying economics at Columbia University. Johnson renounced his US citizenship in 2016, likely to avoid the capital gains taxes Uncle Sam levies on expat American citizens. He has English, French, Swiss, Russian and Lithuanian Jewish heritage, and his paternal great-grandfather was a prominent Turkish journalist and politician.\", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"Prime Minister of the United Kingdom and leader of the Conservative Party.\", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"is to be the U.K.'s next prime minister but the charismatic and controversial figure will already divides the party and British public \", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"is one of Britain's most famous politicians and was a leading figure of the successful Brexit campaign.\", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}}),\n",
        "    (\"became Prime Minister on 24 July 2019. He was previously Foreign Secretary from 13 July 2016 to 9 July 2018. He was elected Conservative MP\", {\"cats\": {\"POSITIVE\": 0.0, \"NEGATIVE\": 1.0}})  \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fIWMkwqHXQo",
        "colab_type": "text"
      },
      "source": [
        "The `trf_textcat` component is based on spaCy's built-in TextCategorizer and supports using the features assigned by the transformer models, via the `trf_tok2vec` component. This lets you use a model like BERT to predict contextual token representations, and then learn a text categorizer on top as a task-specific \"head\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TO7TS2A7hYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd1790ca-2f43-4476-fe19-4ec80a7b16e0"
      },
      "source": [
        "import spacy\n",
        "from spacy.util import minibatch\n",
        "import random\n",
        "import torch\n",
        "\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
        "print(nlp.pipe_names) # [\"sentencizer\", \"trf_wordpiecer\", \"trf_tok2vec\"]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBlvQ51NH6ei",
        "colab_type": "text"
      },
      "source": [
        "Include the `trf_textcat` component. This component is developed internally of spaCy. This is a categorizer. For this reason, you should include the label for the categorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJogXXVU8Jrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4976ded9-f3af-412e-86f3-46b7c47f979e"
      },
      "source": [
        "if \"trf_textcat\" not in nlp.pipe_names:\n",
        "  textcat = nlp.create_pipe(\"trf_textcat\", config={\"exclusive_classes\": True})\n",
        "  for label in (\"POSITIVE\", \"NEGATIVE\"):\n",
        "      textcat.add_label(label)\n",
        "  nlp.add_pipe(textcat)\n",
        "print(nlp.pipe_names) # [\"sentencizer\", \"trf_wordpiecer\", \"trf_tok2vec\"]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec', 'trf_textcat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLHwZVTlPRS9",
        "colab_type": "text"
      },
      "source": [
        "Train the classifier with the training data. For this, spaCy has the `nlp.update` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkf9207C7zZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "69d6f111-97f1-488c-dc85-d9ca56562301"
      },
      "source": [
        "optimizer = nlp.resume_training()\n",
        "for i in range(20):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    for batch in minibatch(TRAIN_DATA, size=8):\n",
        "        texts, cats = zip(*batch)\n",
        "        nlp.update(texts, cats, sgd=optimizer, losses=losses)\n",
        "    print(i, losses)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'trf_textcat': 0.0211661821231246}\n",
            "1 {'trf_textcat': 0.008601571433246136}\n",
            "2 {'trf_textcat': 0.0005061183619545773}\n",
            "3 {'trf_textcat': 2.357704215683043e-05}\n",
            "4 {'trf_textcat': 1.6146023540386523e-06}\n",
            "5 {'trf_textcat': 0.006042719430276122}\n",
            "6 {'trf_textcat': 0.04471092019230127}\n",
            "7 {'trf_textcat': 0.028651805594563484}\n",
            "8 {'trf_textcat': 0.050194691866636276}\n",
            "9 {'trf_textcat': 0.03716572746634483}\n",
            "10 {'trf_textcat': 0.03427313361316919}\n",
            "11 {'trf_textcat': 0.023082171566784382}\n",
            "12 {'trf_textcat': 0.026277894154191017}\n",
            "13 {'trf_textcat': 0.024077199399471283}\n",
            "14 {'trf_textcat': 0.02029687538743019}\n",
            "15 {'trf_textcat': 0.021693839691579342}\n",
            "16 {'trf_textcat': 0.025801432318985462}\n",
            "17 {'trf_textcat': 0.021130203269422054}\n",
            "18 {'trf_textcat': 0.022423338145017624}\n",
            "19 {'trf_textcat': 0.023525687865912914}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9Lb7rNSX0e",
        "colab_type": "text"
      },
      "source": [
        "Test the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRbevBD7QV80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EVALUATION_DATA = [\n",
        "              \"a small, furry, carnivorous animal often kept as a pet\",\n",
        "              \"a small, lithe, soft-furred animal (Felis cattus) of this family, domesticated since ancient times and often kept as a pet or for killing mice\",\n",
        "              \"has been the Prime Minister of the United Kingdom and Leader of the Conservative Party since July 2019. \",\n",
        "              \"is the most popular Conservative politician and the most famous. He is described by fans as: Conservative, Confident, Humorous, ...\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrG7R2x5PbUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "aa829c37-32c5-4876-ff6a-0b9663633424"
      },
      "source": [
        "for eval_test in EVALUATION_DATA:\n",
        "  doc = nlp(eval_test)\n",
        "  print(f' TEXT : {eval_test}')\n",
        "  print(f' CAT : {doc.cats}')\n",
        "  print('---')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " TEXT : a small, furry, carnivorous animal often kept as a pet\n",
            " CAT : {'POSITIVE': 0.5505148768424988, 'NEGATIVE': 0.44948509335517883}\n",
            "---\n",
            " TEXT : a small, lithe, soft-furred animal (Felis cattus) of this family, domesticated since ancient times and often kept as a pet or for killing mice\n",
            " CAT : {'POSITIVE': 0.5505148768424988, 'NEGATIVE': 0.44948509335517883}\n",
            "---\n",
            " TEXT : has been the Prime Minister of the United Kingdom and Leader of the Conservative Party since July 2019. \n",
            " CAT : {'POSITIVE': 0.5505149364471436, 'NEGATIVE': 0.44948509335517883}\n",
            "---\n",
            " TEXT : is the most popular Conservative politician and the most famous. Boris Johnson is described by fans as: Conservative, Confident, Humorous, ...\n",
            " CAT : {'POSITIVE': 0.5505148768424988, 'NEGATIVE': 0.44948509335517883}\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD-4ADfHbLCt",
        "colab_type": "text"
      },
      "source": [
        "*The result seems be a bit bad! Probably I don't have enought training data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTP50hhoSf0K",
        "colab_type": "text"
      },
      "source": [
        "Store the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVI2mJqu8G6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp.to_disk(\"/bert-textcat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drl4_ATgTxxP",
        "colab_type": "text"
      },
      "source": [
        "Use the stored model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo8lmybQS2nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c49478c-1f64-4caf-8347-33355592c5c4"
      },
      "source": [
        "nlp_berttextcat = nlp.from_disk(\"/bert-textcat\")\n",
        "doc = nlp_berttextcat(\"Alexander Boris is a British politician, writer, and former journalist who has served as Prime Minister of the United Kingdom \")\n",
        "print(f' CAT : {doc.cats}')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " CAT : {'POSITIVE': 0.5505148768424988, 'NEGATIVE': 0.44948509335517883}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}