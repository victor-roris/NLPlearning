{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy Transformers - Train Text Categorizer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/Spacy_Transformers_Train_Text_Categorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Q4maVrrfAT",
        "colab_type": "text"
      },
      "source": [
        "# Spacy Transformers - Train Text Categorizer\n",
        "\n",
        "spaCy includes the Transformer models (bert, xlnet). One of the new components of this new spaCy's code is the `trf_textcat`. With this component you can train a NLP model for a specific classifier task.\n",
        "\n",
        "This notebook is a simplification of the official spaCy notebook example: https://github.com/explosion/spacy-transformers/blob/master/examples/train_textcat.py\n",
        "\n",
        "Here, we train a spaCy Bert model to identify if a film review is positive or negative. We use the IMDB dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdQQfda7fg_G",
        "colab_type": "text"
      },
      "source": [
        "## Install spacy transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD-DGqbRfNj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install spacy-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ro2mPpff7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python -m spacy download en_trf_bertbaseuncased_lg\n",
        "! python -m spacy download en_trf_xlnetbasecased_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQg9afXfm5v",
        "colab_type": "text"
      },
      "source": [
        "Restart the environment after the model was downloaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDfynl40fn_u",
        "colab_type": "text"
      },
      "source": [
        "## Train textcat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APyYB25QmChP",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjoJzCCrfGRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "1f2b2e47-8435-4186-b9ae-ca05ae543df3"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "import plac\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import thinc.extra.datasets\n",
        "import spacy\n",
        "import torch\n",
        "from spacy.util import minibatch\n",
        "import tqdm\n",
        "import unicodedata\n",
        "import wasabi\n",
        "from spacy_transformers.util import cyclic_triangular_rate"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqq0sMFJmEvk",
        "colab_type": "text"
      },
      "source": [
        "Definition of main variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeK8aJTPgneh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = \"en_trf_bertbaseuncased_lg\" # or \"en_trf_xlnetbasecased_lg\"\n",
        "max_wpb=1000\n",
        "n_texts=100\n",
        "learn_rate=2e-5\n",
        "batch_size=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ8_E1rWmISX",
        "colab_type": "text"
      },
      "source": [
        "Use GPU if is possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArS_zaFognhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy.util.fix_random_seed(0)\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1D49ADmyfm",
        "colab_type": "text"
      },
      "source": [
        "**Load data**: we use an example with the IMDB dataset. In the original notebook exist an example to load dataset from local filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq3NhookiPg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "976482e6-79cd-41f5-e331-ec0aa7aec94a"
      },
      "source": [
        "# load the IMDB dataset\n",
        "print(\"Loading IMDB data...\")\n",
        "\n",
        "white_re = re.compile(r\"\\s\\s+\")\n",
        "def preprocess_text(text):\n",
        "    text = text.replace(\"<s>\", \"<open-s-tag>\")\n",
        "    text = text.replace(\"</s>\", \"<close-s-tag>\")\n",
        "    text = white_re.sub(\" \", text).strip()\n",
        "    return \"\".join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", text) if unicodedata.category(c) != \"Mn\"\n",
        "    )\n",
        "\n",
        "def _prepare_partition(text_label_tuples, *, preprocess=False):\n",
        "    texts, labels = zip(*text_label_tuples)\n",
        "    if preprocess:\n",
        "        # Preprocessing can mask errors in our handling of noisy text, so\n",
        "        # we don't want to do it by default\n",
        "        texts = [preprocess_text(text) for text in texts]\n",
        "    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n",
        "    return texts, cats\n",
        "\n",
        "def load_data(*, limit=0, dev_size=2000):\n",
        "    \"\"\"Load data from the IMDB dataset, splitting off a held-out set.\"\"\"\n",
        "    if limit != 0:\n",
        "        limit += dev_size\n",
        "    assert dev_size != 0\n",
        "    train_data, _ = thinc.extra.datasets.imdb(limit=limit)\n",
        "    assert len(train_data) > dev_size\n",
        "    random.shuffle(train_data)\n",
        "    dev_data = train_data[:dev_size]\n",
        "    train_data = train_data[dev_size:]\n",
        "    train_texts, train_labels = _prepare_partition(train_data, preprocess=False)\n",
        "    dev_texts, dev_labels = _prepare_partition(dev_data, preprocess=False)\n",
        "    return (train_texts, train_labels), (dev_texts, dev_labels)\n",
        "\n",
        "(train_texts, train_cats), (eval_texts, eval_cats) = load_data(limit=n_texts)\n",
        "print(f\"Using {len(train_texts)} training docs, {len(eval_texts)} evaluation\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading IMDB data...\n",
            "Using 100 training docs, 2000 evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCiC_mM6jSJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d74fe0ab-d624-4d37-b922-9e62ff3314ac"
      },
      "source": [
        "print(f'Category : {train_cats[0]}')\n",
        "print(f' - {train_texts[0][0:100]}...')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category : {'POSITIVE': False, 'NEGATIVE': True}\n",
            " - To make a good movie you either need excellent actors or an excellent director. You need at least on...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cexcfy2enx_M",
        "colab_type": "text"
      },
      "source": [
        "Adapt the input data to the training model format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6GWLRvEipXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "5359dcec-037a-44e3-cc9a-9bfcc358d802"
      },
      "source": [
        "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
        "train_data[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"To make a good movie you either need excellent actors or an excellent director. You need at least one of the two. In this Eye of the Needle we have none.\\n\\n\\n\\nI don't even remember the name of the director. He mustn't have done much in his career. I like very much Donald Sutherland but he absolutely cannot be the main actor in a movie. He falls short. Sutherland is excellent in a movie when he appears for not more than 15 minutes. I would say for instance that Sutherland was excellent in JFK of Oliver Stone when he talked to Kevin Costner on the bench of a park for 10 minutes non-stop without even taking a breath. Wonderful. But Sutherland being the principal actor in a movie is no good.\\n\\n\\n\\nKate Nelligan? She is probably good for TV series. The DVD is awful. Terrible colors. Terrible light. I couldn't even appreciate the scenery of Storm Island for how lousy the photography was.\\n\\n\\n\\nThis Ken Follett story was good but it's a pity they turned it into an uninteresting movie.\",\n",
              " {'cats': {'NEGATIVE': True, 'POSITIVE': False}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsnkdAFbmSxp",
        "colab_type": "text"
      },
      "source": [
        "**Load spaCy model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KgfC81UgyLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0afa8e7b-4f66-4301-d07d-c69168ecb812"
      },
      "source": [
        "nlp = spacy.load(model)\n",
        "print(f'The initial pipeline components are:  {nlp.pipe_names}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwKRPdYzmc0p",
        "colab_type": "text"
      },
      "source": [
        "**Define trf_textcat**\n",
        "\n",
        "We are going to add the component `trf_textcat` created by spaCy to `transfer learning` of one pre-trained model to a specific task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWA3s1fSgyiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textcat = nlp.create_pipe(\n",
        "        \"trf_textcat\",\n",
        "        config={\"architecture\": \"softmax_last_hidden\", \"words_per_batch\": max_wpb},\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j9u1nBghkjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9cd9deb6-90c7-409b-8ffd-a4ea14927626"
      },
      "source": [
        "# add label to text classifier\n",
        "textcat.add_label(\"POSITIVE\")\n",
        "textcat.add_label(\"NEGATIVE\")\n",
        "pos_label = \"POSITIVE\"\n",
        "print(\"Labels:\", textcat.labels)\n",
        "print(\"Positive label for evaluation:\", pos_label)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels: ('POSITIVE', 'NEGATIVE')\n",
            "Positive label for evaluation: POSITIVE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUS1XbHnjfoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "063545c6-ecd2-4751-ccb5-7d220b9c0df6"
      },
      "source": [
        "nlp.add_pipe(textcat, last=True)\n",
        "print(f'The new pipeline components are:  {nlp.pipe_names}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec', 'trf_textcat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-W-PzhxnJcG",
        "colab_type": "text"
      },
      "source": [
        "**Train model**\n",
        "\n",
        "Initialize configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HUoQPPOjXhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a257c51c-f307-41f4-ece5-b1c1eeac9ab4"
      },
      "source": [
        "# Initialize the TextCategorizer, and create an optimizer.\n",
        "optimizer = nlp.resume_training()\n",
        "optimizer.alpha = 0.001\n",
        "optimizer.trf_weight_decay = 0.005\n",
        "optimizer.L2 = 0.0\n",
        "learn_rates = cyclic_triangular_rate(\n",
        "    learn_rate / 3, learn_rate * 3, 2 * len(train_data) // batch_size\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_uVdsFnuKI",
        "colab_type": "text"
      },
      "source": [
        "Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kim2PA5OpBQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(nlp, texts, cats, pos_label):\n",
        "    tp = 0.0  # True positives\n",
        "    fp = 0.0  # False positives\n",
        "    fn = 0.0  # False negatives\n",
        "    tn = 0.0  # True negatives\n",
        "    total_words = sum(len(text.split()) for text in texts)\n",
        "    with tqdm.tqdm(total=total_words, leave=False) as pbar:\n",
        "        for i, doc in enumerate(nlp.pipe(texts, batch_size=8)):\n",
        "            gold = cats[i]\n",
        "            for label, score in doc.cats.items():\n",
        "                if label not in gold:\n",
        "                    continue\n",
        "                if label != pos_label:\n",
        "                    continue\n",
        "                if score >= 0.5 and gold[label] >= 0.5:\n",
        "                    tp += 1.0\n",
        "                elif score >= 0.5 and gold[label] < 0.5:\n",
        "                    fp += 1.0\n",
        "                elif score < 0.5 and gold[label] < 0.5:\n",
        "                    tn += 1\n",
        "                elif score < 0.5 and gold[label] >= 0.5:\n",
        "                    fn += 1\n",
        "            pbar.update(len(doc.text.split()))\n",
        "    precision = tp / (tp + fp + 1e-8)\n",
        "    recall = tp / (tp + fn + 1e-8)\n",
        "    if (precision + recall) == 0:\n",
        "        f_score = 0.0\n",
        "    else:\n",
        "        f_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ict2J7FlkM1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ecc09ea4-1be7-4244-eb9a-0b2e13b4b0ab"
      },
      "source": [
        "print(\"Training the model...\")\n",
        "print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "\n",
        "pbar = tqdm.tqdm(total=100, leave=False)\n",
        "results = []\n",
        "epoch = 0\n",
        "step = 0\n",
        "eval_every = 100\n",
        "patience = 3\n",
        "while True:\n",
        "    # Train and evaluate\n",
        "    losses = Counter()\n",
        "    random.shuffle(train_data)\n",
        "    batches = minibatch(train_data, size=batch_size)\n",
        "    for batch in batches:\n",
        "        optimizer.trf_lr = next(learn_rates)\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(texts, annotations, sgd=optimizer, drop=0.1, losses=losses)\n",
        "        pbar.update(1)\n",
        "        if step and (step % eval_every) == 0:\n",
        "            pbar.close()\n",
        "            with nlp.use_params(optimizer.averages):\n",
        "                scores = evaluate(nlp, eval_texts, eval_cats, pos_label)\n",
        "            results.append((scores[\"textcat_f\"], step, epoch))\n",
        "            print(\n",
        "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(\n",
        "                    losses[\"trf_textcat\"],\n",
        "                    scores[\"textcat_p\"],\n",
        "                    scores[\"textcat_r\"],\n",
        "                    scores[\"textcat_f\"],\n",
        "                )\n",
        "            )\n",
        "            pbar = tqdm.tqdm(total=eval_every, leave=False)\n",
        "        step += 1\n",
        "    epoch += 1\n",
        "    # Stop if no improvement in HP.patience checkpoints\n",
        "    if results:\n",
        "        best_score, best_step, best_epoch = max(results)\n",
        "        if ((step - best_step) // eval_every) >= patience:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 53/100 [37:53<28:55, 36.93s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65lDW4Vwkgxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msg = wasabi.Printer()\n",
        "table_widths = [2, 4, 6]\n",
        "msg.info(f\"Best scoring checkpoints\")\n",
        "msg.row([\"Epoch\", \"Step\", \"Score\"], widths=table_widths)\n",
        "msg.row([\"-\" * width for width in table_widths])\n",
        "for score, step, epoch in sorted(results, reverse=True)[:10]:\n",
        "    msg.row([epoch, step, \"%.2f\" % (score * 100)], widths=table_widths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4nhYIa9ovXh",
        "colab_type": "text"
      },
      "source": [
        "**Testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn5FDeAVk2Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Test the trained model\n",
        "test_text = eval_texts[0]\n",
        "doc = nlp(test_text)\n",
        "print(test_text, doc.cats)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}