{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy PyTorch Transformers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/Spacy_PyTorch_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_PfMvdSGHPi",
        "colab_type": "text"
      },
      "source": [
        "# Spacy PyTorch Transformers\n",
        "\n",
        "Notebook with the code extract in some source of Internet. The original code is an adaptation of the fantastic Paco's work.\n",
        "\n",
        "https://github.com/DerwenAI/spaCy_tuTorial/blob/master/spaCy_transformers_demo.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkN1IjPaGIUN",
        "colab_type": "text"
      },
      "source": [
        "## Install and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDKKAcfkQsRR",
        "colab_type": "code",
        "outputId": "93283aa9-58ea-4579-a8fa-65c516b64864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install spacy\n",
        "!pip install spacy-pytorch-transformers\n",
        "!python -m spacy download en_pytt_bertbaseuncased_lg\n",
        "!python -m spacy download en_pytt_xlnetbasecased_lg\n",
        "!pip install numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Collecting spacy-pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.0MB/s \n",
            "\u001b[?25hCollecting dataclasses<0.7,>=0.6; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting ftfy<6.0.0,>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (2.1.9)\n",
            "Collecting pytorch-transformers<1.3.0,>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (0.2.0)\n",
            "Collecting torchcontrib<0.1.0,>=0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (1.3.1+cu100)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers) (0.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (1.17.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (0.4.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (0.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.10.14)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.9MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 46.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.13.14)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.14.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2.6.1)\n",
            "Building wheels for collected packages: ftfy, torchcontrib, sacremoses\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=779277c4c0f03573d57cb2fb1d5ea7becce732f3b1d39841c13571ec0c05e148\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7530 sha256=0650f34427948085bf0fab8f4bdd5ae0e90734917bc52c15e75321ddc05d92d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=003026aa1e1a0feb1d3f724ab6c57d954bef39e79fe8f62a3f4e072cc3979303\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built ftfy torchcontrib sacremoses\n",
            "Installing collected packages: dataclasses, ftfy, sentencepiece, regex, sacremoses, pytorch-transformers, torchcontrib, spacy-pytorch-transformers\n",
            "  Found existing installation: dataclasses 0.7\n",
            "    Uninstalling dataclasses-0.7:\n",
            "      Successfully uninstalled dataclasses-0.7\n",
            "Successfully installed dataclasses-0.6 ftfy-5.6 pytorch-transformers-1.2.0 regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 spacy-pytorch-transformers-0.4.0 torchcontrib-0.0.2\n",
            "Collecting en_pytt_bertbaseuncased_lg==2.1.1\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_bertbaseuncased_lg-2.1.1/en_pytt_bertbaseuncased_lg-2.1.1.tar.gz (405.8MB)\n",
            "\u001b[K     |████████████████████████████████| 405.8MB 45.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-pytt-bertbaseuncased-lg\n",
            "  Building wheel for en-pytt-bertbaseuncased-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-pytt-bertbaseuncased-lg: filename=en_pytt_bertbaseuncased_lg-2.1.1-cp36-none-any.whl size=405820502 sha256=aa17d2eecab4cc5992d37e875a0bcddb1e8579a1943cd04790fb7076b324ec61\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lw1bbo4v/wheels/22/9c/d5/f389bff44d5709e468c2c5d32f1f90066cf298a2595c9c4d94\n",
            "Successfully built en-pytt-bertbaseuncased-lg\n",
            "Installing collected packages: en-pytt-bertbaseuncased-lg\n",
            "Successfully installed en-pytt-bertbaseuncased-lg-2.1.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_pytt_bertbaseuncased_lg')\n",
            "Collecting en_pytt_xlnetbasecased_lg==2.1.1\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz (433.9MB)\n",
            "\u001b[K     |████████████████████████████████| 433.9MB 62.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-pytt-xlnetbasecased-lg\n",
            "  Building wheel for en-pytt-xlnetbasecased-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-pytt-xlnetbasecased-lg: filename=en_pytt_xlnetbasecased_lg-2.1.1-cp36-none-any.whl size=433909581 sha256=9b6a347dd57a0df47b51f242305612246c18b17f95e78111c617f067751538e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p_46x8l6/wheels/30/9b/00/b570788126042185cd1f038f136e29f3a93a8dc824a35f6582\n",
            "Successfully built en-pytt-xlnetbasecased-lg\n",
            "Installing collected packages: en-pytt-xlnetbasecased-lg\n",
            "Successfully installed en-pytt-xlnetbasecased-lg-2.1.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_pytt_xlnetbasecased_lg')\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LVdBbxAQtw2",
        "colab_type": "code",
        "outputId": "0f662785-24d1-4b23-a44f-4e2fd132242b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install -q torch==1.1.0 torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 676.9MB 5.4kB/s \n",
            "\u001b[31mERROR: torchvision 0.4.2+cu100 has requirement torch==1.3.1, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfr-F6mwGRFX",
        "colab_type": "text"
      },
      "source": [
        "Use GPU if is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb38QiRPQwdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "from numpy.testing import assert_almost_equal\n",
        "\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_YKvIk6GdzV",
        "colab_type": "text"
      },
      "source": [
        "Load spacy Bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyWkcUTGWor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_pytt_bertbaseuncased_lg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3dGh6LUGiWl",
        "colab_type": "text"
      },
      "source": [
        "Tokenize text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jUE5yF4TN5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"Here is some text to encode.\")\n",
        "assert doc.tensor.shape == (7, 768)  # Always has one row per token including punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QDQ9SNTXm2",
        "colab_type": "code",
        "outputId": "87920724-c129-4a4e-d7f1-0d96d966a03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(doc._.pytt_word_pieces_)  # String values of the wordpieces\n",
        "print(doc._.pytt_word_pieces)  # Wordpiece IDs (note: *not* spaCy's hash values!)\n",
        "print(doc._.pytt_alignment)  # Alignment between spaCy tokens and wordpieces\n",
        "\n",
        "# The raw transformer output has one row per wordpiece.\n",
        "assert len(doc._.pytt_last_hidden_state) == len(doc._.pytt_word_pieces)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'here', 'is', 'some', 'text', 'to', 'en', '##code', '.', '[SEP]']\n",
            "[101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 1012, 102]\n",
            "[[1], [2], [3], [4], [5], [6, 7], [8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-_UdiiqTdDs",
        "colab_type": "code",
        "outputId": "b2e7e983-9308-450b-caff-8a6fd162e261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# To avoid losing information, we calculate the doc.tensor attribute such that\n",
        "# the sum-pooled vectors match (apart from numeric error)\n",
        "tensor_sum = doc.tensor.sum(axis=1)\n",
        "last_hidden_state_sum = doc._.pytt_last_hidden_state.sum(axis=1)\n",
        "print(f\"tensor_sum = {tensor_sum}, shape = {tensor_sum.shape}\")\n",
        "print(f\"last_hidden_state_sum = {last_hidden_state_sum}, shape={last_hidden_state_sum.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor_sum = [-12.914995 -15.33556  -11.52346  -10.473546 -10.937901 -24.572096\n",
            " -13.70007 ], shape = (7,)\n",
            "last_hidden_state_sum = [ -8.03236    -9.845612  -12.266172   -8.454072   -7.4041576  -7.868512\n",
            " -11.894537   -9.608173  -10.630686  -13.453345 ], shape=(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db-gJxqTTxsm",
        "colab_type": "code",
        "outputId": "c53da4e5-8682-43d1-ed4f-ae821856a66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "span = doc[2:4]\n",
        "print(f'SPAN = {span.text}')\n",
        "print(f\"span.tensor = {span.tensor}, shape = {span.tensor.shape}\")\n",
        "doc_tensor = doc.tensor[2:4]\n",
        "print(f\"doc.tensor = {doc_tensor}, shape = {doc_tensor.shape}\")\n",
        "# Access the tensor from Span elements (especially helpful for sentences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SPAN = some text\n",
            "span.tensor = [[ 0.0759325  -0.4535255   0.24927723 ...  0.28133303 -0.45936924\n",
            "   0.83061355]\n",
            " [ 0.19304082  0.32884982  0.38221556 ... -0.2427446  -0.18937269\n",
            "   0.50180256]], shape = (2, 768)\n",
            "doc.tensor = [[ 0.0759325  -0.4535255   0.24927723 ...  0.28133303 -0.45936924\n",
            "   0.83061355]\n",
            " [ 0.19304082  0.32884982  0.38221556 ... -0.2427446  -0.18937269\n",
            "   0.50180256]], shape = (2, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfQIZD1HJTvR",
        "colab_type": "text"
      },
      "source": [
        "## Similarity comparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsdITVgpJ7T7",
        "colab_type": "text"
      },
      "source": [
        "### Testing with BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n1XFyyKKAP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_pytt_bertbaseuncased_lg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lyinEchUML9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_nlp(nlp1, nlp2):\n",
        "  print(f\"comparing '{nlp1}' vs '{nlp2}': {nlp1.similarity(nlp2)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAuYqxLPWT-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_apples():\n",
        "  # .vector and .similarity use the transformer outputs\n",
        "  apple1 = nlp(\"Apple shares rose on the news.\")\n",
        "  print(f\"apple1 shape: {apple1[1].vector.shape} \")\n",
        "  apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
        "  apple3 = nlp(\"Apple pie is delicious.\")\n",
        "\n",
        "  #Compare sentences\n",
        "  compare_nlp(apple1, apple2)\n",
        "  compare_nlp(apple1, apple3)\n",
        "  \n",
        "  #Compare words by sentence context\n",
        "  compare_nlp(apple1[0], apple2[0])\n",
        "  compare_nlp(apple1[0], apple3[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4TaEHrhWhfb",
        "colab_type": "code",
        "outputId": "c1f412ec-f172-4ded-8977-2a1d6e31cc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test_apples()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple1 shape: (768,) \n",
            "comparing 'Apple shares rose on the news.' vs 'Apple sold fewer iPhones this quarter.': 0.6986121627144829\n",
            "comparing 'Apple shares rose on the news.' vs 'Apple pie is delicious.': 0.5404962512345809\n",
            "comparing 'Apple' vs 'Apple': 0.7342854142189026\n",
            "comparing 'Apple' vs 'Apple': 0.43365713953971863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av_EphWMWjqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_bank_sentences():\n",
        "  bank1 = nlp(\"The banks of the river burst.\")\n",
        "  bank2 = nlp(\"The banks are closed today.\")\n",
        "  bank3 = nlp(\"The boys were fishing along the riverbank.\")\n",
        "\n",
        "  #Compare sentences\n",
        "  compare_nlp(bank1, bank2)\n",
        "  compare_nlp(bank1, bank3)\n",
        "\n",
        "  #Compare words by sentence context\n",
        "  compare_nlp(bank1[1], bank2[1])\n",
        "  compare_nlp(bank1[1], bank3[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK9SYmAvWx4o",
        "colab_type": "code",
        "outputId": "cbd7c982-feda-423d-be09-bc1e5b1dfe49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "test_bank_sentences()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comparing 'The banks of the river burst.' vs 'The banks are closed today.': 0.6167170223363752\n",
            "comparing 'The banks of the river burst.' vs 'The boys were fishing along the riverbank.': 0.666211196578021\n",
            "comparing 'banks' vs 'banks': 0.5826777219772339\n",
            "comparing 'banks' vs 'riverbank': 0.6132599115371704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOK6cQX8KCum",
        "colab_type": "text"
      },
      "source": [
        "### Testing with XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD_jApBJWy0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model():\n",
        "  test_apples()\n",
        "  test_bank_sentences()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Gthlw1XP_O",
        "colab_type": "code",
        "outputId": "00af9da8-948f-499a-dbdc-e45dcc90aa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# Redo with XLNet\n",
        "nlp = spacy.load(\"en_pytt_xlnetbasecased_lg\")\n",
        "\n",
        "test_model()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple1 shape: (768,) \n",
            "comparing 'Apple shares rose on the news.' vs 'Apple sold fewer iPhones this quarter.': 0.991628388620012\n",
            "comparing 'Apple shares rose on the news.' vs 'Apple pie is delicious.': 0.9804112023332523\n",
            "comparing 'Apple' vs 'Apple': 0.9853271842002869\n",
            "comparing 'Apple' vs 'Apple': 0.9792127013206482\n",
            "comparing 'The banks of the river burst.' vs 'The banks are closed today.': 0.9783249649400636\n",
            "comparing 'The banks of the river burst.' vs 'The boys were fishing along the riverbank.': 0.9844713596787769\n",
            "comparing 'banks' vs 'banks': 0.9692249298095703\n",
            "comparing 'banks' vs 'riverbank': 0.982304036617279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2eo804XRUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}