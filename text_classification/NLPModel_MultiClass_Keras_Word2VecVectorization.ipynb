{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPModel_MultiClass_Keras_Word2VecVectorization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/NLPModel_MultiClass_Keras_Word2VecVectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s3Lj1Y8MxNU",
        "colab_type": "text"
      },
      "source": [
        "# NLP Model with Word2Vec and Keras\n",
        "\n",
        "In this notebook, we are going to use a Keras Model to predict categories of text. To vectorize the text we are going to use the Word2Vec model.\n",
        "\n",
        "We train Word2Vec embedding with our own dataset.\n",
        "\n",
        "Notebook adapted from:\n",
        "\n",
        "https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbifrxFwd0u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jXaFiuRZug_",
        "colab_type": "text"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iifyu9FFDsVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d74cccff-d99a-4a44-e3d0-49ec5906623a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/SrinidhiRaghavan/AI-Sentiment-Analysis-on-IMDB-Dataset/master/imdb_tr.csv',  encoding = \"ISO-8859-1\")\n",
        "\n",
        "print(f'Number of examples : {len(df)}')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples : 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_Number</th>\n",
              "      <th>text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2148</td>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23577</td>\n",
              "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1319</td>\n",
              "      <td>big fan Stephen King's work, film made even gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13358</td>\n",
              "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9495</td>\n",
              "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_Number                                               text  polarity\n",
              "0        2148  first think another Disney movie, might good, ...         1\n",
              "1       23577  Put aside Dr. House repeat missed, Desperate H...         0\n",
              "2        1319  big fan Stephen King's work, film made even gr...         1\n",
              "3       13358  watched horrid thing TV. Needless say one movi...         0\n",
              "4        9495  truly enjoyed film. acting terrific plot. Jeff...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SscAvrafZyvf",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec Embedding\n",
        "\n",
        "In particular, in this implementation we apply the Word2Vec techinques to calculate our own embedding in the current dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKgXQ0kfb1Dq",
        "colab_type": "text"
      },
      "source": [
        "Creating word tokens, removing punctuation, removing stop words etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qypep8CLbOyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ae94b4ee-1a85-4fea-e688-abbbc24df135"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVx_hd51HvRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "eed6c109-0a5a-43b6-8b29-06be568b1980"
      },
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "review_lines = list()\n",
        "lines = df['text'].values.tolist()\n",
        "\n",
        "for line in lines:\n",
        "  tokens = word_tokenize(line)\n",
        "\n",
        "  #convert to lower case\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "\n",
        "  #remove punctuation from each word\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "\n",
        "  #remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "\n",
        "  #filter out stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  \n",
        "  review_lines.append(words)\n",
        "\n",
        "print(f'Example of tokenize text : {review_lines[0]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of tokenize text : ['first', 'think', 'another', 'disney', 'movie', 'might', 'good', 'kids', 'movie', 'watch', 'ca', 'nt', 'help', 'enjoy', 'ages', 'love', 'movie', 'first', 'saw', 'movie', 'years', 'later', 'still', 'love', 'danny', 'glover', 'superb', 'could', 'play', 'part', 'better', 'christopher', 'lloyd', 'hilarious', 'perfect', 'part', 'tony', 'danza', 'believable', 'mel', 'clark', 'ca', 'nt', 'help', 'enjoy', 'movie', 'give']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbEolffBcO3n",
        "colab_type": "text"
      },
      "source": [
        "We will use the Gensim implementation of Word2Vec. The word2vec algorithm processes documents sentence by sentence.\n",
        "\n",
        "Gensim’s Word2Vec API requires some parameters for initialization.\n",
        " - `sentences` – List of sentences; here we pass the list of review sentences.\n",
        " - `size` – The number of dimensions in which we wish to represent our word. This is the size of the word vector.\n",
        " - `min_count` – Word with frequency greater than min_count only are going to be included into the model. Usually, the bigger and more extensive your text, the higher this number can be.\n",
        " - `window` – Only terms that occur within a window-neighborhood of a term, in a sentence, are associated with it during training. The usual value is 4 or 5.\n",
        " - `workers` – Number of threads used in training parallelization, to speed up training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTYE27gLbMGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "deb8e878-6b69-40af-ca14-e7c74fc09206"
      },
      "source": [
        "import gensim\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "#train word2vec model\n",
        "model = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=5, workers=4, min_count=1)\n",
        "\n",
        "#vocab size\n",
        "words = list(model.wv.vocab)\n",
        "print(f'Vocabulary size: {len(words)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 93058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH6kxBmzchDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "10060045-8c82-4239-c718-45bb71926067"
      },
      "source": [
        "print('Word2Vec similar words for \"horrible\"')\n",
        "model.wv.most_similar('horrible')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec similar words for \"horrible\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.9547101259231567),\n",
              " ('awful', 0.9289554357528687),\n",
              " ('sucks', 0.8766037225723267),\n",
              " ('atrocious', 0.843876838684082),\n",
              " ('sucked', 0.8312643766403198),\n",
              " ('crappy', 0.8228499889373779),\n",
              " ('horrendous', 0.8225404024124146),\n",
              " ('dreadful', 0.8206788897514343),\n",
              " ('laughable', 0.8203979730606079),\n",
              " ('stupid', 0.8178586959838867)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4-Fw-H1c9Pp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4a140988-21cf-4163-ec0e-b5e41ede68ed"
      },
      "source": [
        "#Let's see the result of semantically reasonable word vectors (brother - man + woman)\n",
        "\n",
        "print(f'Word2Vec result of semantically reasonable word vectors (brother - man + woman) :')\n",
        "model.wv.most_similar_cosmul(positive=['brother', 'woman'], negative=['man'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec result of semantically reasonable word vectors (brother - man + woman) :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sister', 1.1465065479278564),\n",
              " ('daughter', 1.1121941804885864),\n",
              " ('boyfriend', 1.0967283248901367),\n",
              " ('son', 1.0912766456604004),\n",
              " ('wife', 1.0800729990005493),\n",
              " ('father', 1.076292634010315),\n",
              " ('marie', 1.0708884000778198),\n",
              " ('girlfriend', 1.0669641494750977),\n",
              " ('mother', 1.0638612508773804),\n",
              " ('husband', 1.0607103109359741)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fva2YCq8eFQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c6e658db-4c4f-4205-988f-faa2388cbef6"
      },
      "source": [
        "\n",
        "print(f'Word2Vec result of find the odd word in \"actor\", \"director\", \"actress\" and \"foot\" : ')\n",
        "model.wv.doesnt_match(\"actor director actress foot\".split())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec result of find the odd word in \"actor\", \"director\", \"actress\" and \"foot\" : \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIiBcFBrfc7y",
        "colab_type": "text"
      },
      "source": [
        "You can save your Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRT76SarfChq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "filename = \"imdb_embedding_word2vec.txt\"\n",
        "model.wv.save_word2vec_format(filename, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J4-SAzhftrA",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8NnEbdqf8fN",
        "colab_type": "text"
      },
      "source": [
        "Since we have already trained word2vec model with IMDb dataset, we have the word embeddings ready to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZqUxiAnfyaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the saved W2V model\n",
        "\n",
        "import os\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('', 'imdb_embedding_word2vec.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:])\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLt4wLXXhVfh",
        "colab_type": "text"
      },
      "source": [
        "The next step is to convert the word embedding into tokenized vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ukihZmdhV5Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a2a65ff5-6462-49b1-af8c-04c21e149bcb"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# vectorize the text samples into a 2D integer tensor\n",
        "\n",
        "# Train the tokenizer (vectorizer) with the tokenized word text\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(review_lines)\n",
        "\n",
        "# Convert to sequence the text\n",
        "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
        "\n",
        "print(f'Vectorized {len(sequences)} sequences of text')\n",
        "\n",
        "print('Example of vectorized text :')\n",
        "print(f'Tokenized text ({len(review_lines[0])} entries) : {review_lines[0]}')\n",
        "print(f'Vectorized text ({len(sequences[0])} entries) : {sequences[0]}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Vectorized 25000 sequences of text\n",
            "Example of vectorized text :\n",
            "Tokenized text (47 entries) : ['first', 'think', 'another', 'disney', 'movie', 'might', 'good', 'kids', 'movie', 'watch', 'ca', 'nt', 'help', 'enjoy', 'ages', 'love', 'movie', 'first', 'saw', 'movie', 'years', 'later', 'still', 'love', 'danny', 'glover', 'superb', 'could', 'play', 'part', 'better', 'christopher', 'lloyd', 'hilarious', 'perfect', 'part', 'tony', 'danza', 'believable', 'mel', 'clark', 'ca', 'nt', 'help', 'enjoy', 'movie', 'give']\n",
            "Vectorized text (47 entries) : [22, 27, 61, 673, 2, 124, 7, 227, 2, 30, 87, 4, 214, 232, 1868, 40, 2, 22, 106, 2, 59, 183, 47, 40, 1432, 2989, 741, 16, 187, 76, 45, 1151, 3042, 491, 278, 76, 932, 10915, 701, 3466, 2260, 87, 4, 214, 232, 2, 93]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg3WV-D-ioiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bf192ba-6546-466a-94e3-5a9462903dbb"
      },
      "source": [
        "# pad sequences\n",
        "word_index = tokenizer_obj.word_index\n",
        "print(f'Found {len(word_index)} unique tokens.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 93058 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsI5eRqAisII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2b637d07-3eac-4be5-9a14-a9fc769f70c7"
      },
      "source": [
        "max_length = max([len(s) for s in review_lines]) # The max length is the length of the most text with more words\n",
        "\n",
        "print(f'Text with more words : {max_length}')\n",
        "\n",
        "# Pad all the sequences in the same length (fill in with 0 the short sequences or cut the longer sequences)\n",
        "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "print(f'The padding sequences are expresed in a list of {review_pad.shape[0]} entries (examples) where each entry is a list of {review_pad.shape[1]} tokens (pad with 0 in the shorter sequences)')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text with more words : 1440\n",
            "The padding sequences are expresed in a list of 25000 entries (examples) where each entry is a list of 1440 tokens (pad with 0 in the shorter sequences)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-kCYOmUkE8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df['polarity'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCD5MIH3knmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "18bd3e88-4804-43e4-d8f2-14d86d815476"
      },
      "source": [
        "print(f'Shape of review tensor : { review_pad.shape }')\n",
        "print(f'Shape of sentiment tensor: {labels.shape}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of review tensor : (25000, 1440)\n",
            "Shape of sentiment tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IENtb_JMl9kt",
        "colab_type": "text"
      },
      "source": [
        "Now we will map embeddings from the loaded word2vec model for each word to the `tokenizer_obj.word_index` vocabulary and create a matrix with of word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fysm1i8-l0iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d32ef10f-c570-4454-b57d-205b2bbb6084"
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros( (num_words, EMBEDDING_DIM) )\n",
        "\n",
        "print(f\"We create a embedding matrix of shape ({embedding_matrix.shape[0]} words) x ({embedding_matrix.shape[1]} features)\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We create a embedding matrix of shape (93059 words) x (100 features)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpaUWXvM7KNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNZc22_7BEN5",
        "colab_type": "text"
      },
      "source": [
        "We are now ready with the trained embedding vector to be used directly in the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3yczu4A_ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "0ae53256-4242-4f3c-ddda-a16a075db669"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "#define model\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VfweYQUJTGO",
        "colab_type": "text"
      },
      "source": [
        "To train the sentiment classification model, we use VALIDATION_SPLIT= 0.2, you can vary this to see effect on the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAHSmQgZCDD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomize the examples\n",
        "indices = np.arange(review_pad.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "review_pad = review_pad[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qnPlaFRKUOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61c8ba51-4646-4472-e644-b9efadbddce4"
      },
      "source": [
        "# split the data into a training set and validation set\n",
        "VALIDATION_SPLIT = 0.2\n",
        "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
        "\n",
        "print(num_validation_samples)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD-YJd8vKrG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "2320a72f-4001-488d-bcf4-a3cca98fc53d"
      },
      "source": [
        "X_train_pad = review_pad[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "X_test_pad = review_pad[-num_validation_samples:]\n",
        "y_test = labels[-num_validation_samples:]\n",
        "\n",
        "print(f'Number of training examples : {len(y_train)} ')\n",
        "print(f'Number of test examples : {len(y_test)} ')\n",
        "print(f'Shape of training examples : {X_train_pad.shape}')\n",
        "print(f'Shape of test examples : {X_test_pad.shape}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples : 20000 \n",
            "Number of test examples : 5000 \n",
            "Shape of training examples : (20000, 1440)\n",
            "Shape of test examples : (5000, 1440)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27NMNhHuLAlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "47e0a222-e018-4300-da18-362a149a8592"
      },
      "source": [
        "print('Train ...')\n",
        "model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_test_pad, y_test), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 255s - loss: 0.6010 - acc: 0.6642 - val_loss: 0.4375 - val_acc: 0.8018\n",
            "Epoch 2/25\n",
            " - 253s - loss: 0.4476 - acc: 0.7963 - val_loss: 0.3513 - val_acc: 0.8502\n",
            "Epoch 3/25\n",
            " - 253s - loss: 0.3951 - acc: 0.8266 - val_loss: 0.3339 - val_acc: 0.8566\n",
            "Epoch 4/25\n",
            " - 253s - loss: 0.3730 - acc: 0.8418 - val_loss: 0.3238 - val_acc: 0.8636\n",
            "Epoch 5/25\n",
            " - 254s - loss: 0.3570 - acc: 0.8470 - val_loss: 0.3136 - val_acc: 0.8664\n",
            "Epoch 6/25\n",
            " - 254s - loss: 0.3455 - acc: 0.8524 - val_loss: 0.3073 - val_acc: 0.8706\n",
            "Epoch 7/25\n",
            " - 252s - loss: 0.3415 - acc: 0.8548 - val_loss: 0.3012 - val_acc: 0.8714\n",
            "Epoch 8/25\n",
            " - 252s - loss: 0.3310 - acc: 0.8599 - val_loss: 0.3002 - val_acc: 0.8744\n",
            "Epoch 9/25\n",
            " - 255s - loss: 0.3253 - acc: 0.8609 - val_loss: 0.2974 - val_acc: 0.8738\n",
            "Epoch 10/25\n",
            " - 252s - loss: 0.3232 - acc: 0.8648 - val_loss: 0.2939 - val_acc: 0.8754\n",
            "Epoch 11/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CpyQMcxNzfO",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYQYmeZfMZW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = logreg.predict(test_vectors_dbow)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=categories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BvDljCN8df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "# This utility function is from the sklearn docs: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=30)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, fontsize=22)\n",
        "    plt.yticks(tick_marks, classes, fontsize=22)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=25)\n",
        "    plt.xlabel('Predicted label', fontsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjAYvC2cN82J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(24,13))\n",
        "plot_confusion_matrix(cnf_matrix, classes=categories, title=\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq5-2-LFN_sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
