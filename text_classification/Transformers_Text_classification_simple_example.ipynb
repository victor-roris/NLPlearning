{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers - Text classification simple example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a518b1fa2644ca2bd60f8075827c47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d68bfae0d3aa4865a34b2b3d42ab1cd5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0337641eff9245bdb0d53c4ae19b1062",
              "IPY_MODEL_67b5a8880dbb41ac99a6a16ef203446c",
              "IPY_MODEL_4074be407d84454194c3d92f3f961e1d"
            ]
          }
        },
        "d68bfae0d3aa4865a34b2b3d42ab1cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0337641eff9245bdb0d53c4ae19b1062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4925de119339430b95fcf20a5ebcdd27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2e2b123ced44ea28284eb2b2a5939bc"
          }
        },
        "67b5a8880dbb41ac99a6a16ef203446c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10b749375a30475e9474fba424ce566a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d96d63299d94490bafb86ac28ad70d03"
          }
        },
        "4074be407d84454194c3d92f3f961e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9487dda0f18a434eabd5278b695a4ea5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 47.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f047e48f7f3f4d11bcb628e9f923539a"
          }
        },
        "4925de119339430b95fcf20a5ebcdd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2e2b123ced44ea28284eb2b2a5939bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10b749375a30475e9474fba424ce566a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d96d63299d94490bafb86ac28ad70d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9487dda0f18a434eabd5278b695a4ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f047e48f7f3f4d11bcb628e9f923539a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/NLPlearning/blob/master/text_classification/Transformers_Text_classification_simple_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3U3AIIqVUmp"
      },
      "source": [
        "# Text Classification using Transformer library\n",
        "\n",
        "Transformers library ([documentation page](https://huggingface.co/transformers/master/quicktour.html) | [github page](https://github.com/huggingface/transformers)):\n",
        "\n",
        "- Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "- Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.\n",
        "\n",
        "- Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1mh-WXbI4ar"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyu3vMXfWTiW"
      },
      "source": [
        "In this notebook we use a `PyTorch` implementation of a text classification model where we use as input a simple dataset where each entry has a text and label associated. \n",
        "\n",
        "This notebook is adaptation of [this notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/custom_datasets.ipynb#scrollTo=8QALcXp68zcL) and [this notebook](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcW1jx4z0Puk"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "As example input we use the IMDB dataset ([link](https://huggingface.co/datasets/imdb)). Large Movie Review Dataset. This is a dataset for binary sentiment classification.\n",
        "\n",
        "We will use the huggingface Datasets library to download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ8t7aRHTZ7i"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "7a518b1fa2644ca2bd60f8075827c47c",
            "d68bfae0d3aa4865a34b2b3d42ab1cd5",
            "0337641eff9245bdb0d53c4ae19b1062",
            "67b5a8880dbb41ac99a6a16ef203446c",
            "4074be407d84454194c3d92f3f961e1d",
            "4925de119339430b95fcf20a5ebcdd27",
            "a2e2b123ced44ea28284eb2b2a5939bc",
            "10b749375a30475e9474fba424ce566a",
            "d96d63299d94490bafb86ac28ad70d03",
            "9487dda0f18a434eabd5278b695a4ea5",
            "f047e48f7f3f4d11bcb628e9f923539a"
          ]
        },
        "id": "PcsLATLx0Xqw",
        "outputId": "6b2ab9c9-7a55-473d-e469-aa2fe6b67c59"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a518b1fa2644ca2bd60f8075827c47c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1EQznBg0XyU",
        "outputId": "1d442ac4-82a8-4336-e851-97adce70a034"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJAju0Ewe5x",
        "outputId": "efcc8bff-0332-4809-d71b-1ac9254a3b88"
      },
      "source": [
        "dataset[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEnBQhJu7_4E"
      },
      "source": [
        "train_texts, train_labels = dataset[\"train\"][\"text\"], dataset[\"train\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"text\"], dataset[\"test\"][\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2lyoM34Wx92"
      },
      "source": [
        "# Limit to train it fast\n",
        "train_texts = train_texts[:200]\n",
        "train_labels = train_labels[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPlfIvrfBnW5"
      },
      "source": [
        "## Fine-tuning Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVHrgNpDBL1"
      },
      "source": [
        "#### 1. Identify the task ([list of available tasks](https://huggingface.co/transformers/task_summary.html)):\n",
        "\n",
        " - TextClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNl_OGsWDrHP"
      },
      "source": [
        "#### 2. Select a pretrained model ([list of available pretrained models](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads))\n",
        "- [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRGaqlaFD7iO"
      },
      "source": [
        "model_checkpoint = \"distilbert-base-uncased\"   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Rz0xajFFyH"
      },
      "source": [
        "#### 3. Load tokenizer and model for text classification\n",
        "- Tokenizer documentation [page](https://huggingface.co/transformers/master/main_classes/tokenizer.html)\n",
        "- Model documentation [page](https://huggingface.co/transformers/master/main_classes/model.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jqyXiLk3F2v",
        "outputId": "5c0e9aed-b678-4668-c88e-9a4566454ebb"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P5gZoLbMet_"
      },
      "source": [
        "Basic examples of usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZVqGsMoLTch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb57ed93-f646-4b26-c00e-cccab40a4436"
      },
      "source": [
        "# Example of usage of the tokenizer\n",
        "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoFJRUNPF1Nc",
        "outputId": "23bf7d29-fed2-4e99-fa26-640e5b399269"
      },
      "source": [
        "# Example of usage of the model\n",
        "pt_batch = tokenizer(\n",
        "     [\"This is an example of usage.\"],\n",
        "     padding=True,\n",
        "     truncation=True,\n",
        "     return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "logits = model(**pt_batch).logits\n",
        "logits.tolist()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11427704989910126, -0.019518937915563583]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMV-6QPl29Tp"
      },
      "source": [
        "####4. Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2lZBZy_hFb"
      },
      "source": [
        "# Tokenize text\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xls_aPtNkUE"
      },
      "source": [
        "Now, let's turn our labels and encodings into a Dataset object. In PyTorch, this is done by subclassing a `torch.utils.data.Dataset` object and implementing `__len__` and `__getitem__`. In TensorFlow, we pass our input encodings and labels to the `from_tensor_slices` constructor method. We put the data in this format so that the data can be easily batched such that each key in the batch encoding corresponds to a named parameter of the `DistilBertForSequenceClassification.forward` method of the model we will train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Mqk0iT0OrC"
      },
      "source": [
        "import torch\n",
        "\n",
        "class IMDbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kij060kVOF_A"
      },
      "source": [
        "####5. Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqwjsBVXOLUk"
      },
      "source": [
        "The `Trainer` and `TFTrainer` classes provide an API for feature-complete training in most standard use cases. [Trainer documentation page](https://huggingface.co/transformers/main_classes/trainer.html).\n",
        "\n",
        "Before instantiating your `Trainer`/`TFTrainer`, create a `TrainingArguments`/`TFTrainingArguments` to access all the points of customization during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YqJRwzGA5J-"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=100,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pSa2m4hX5f2"
      },
      "source": [
        "Then we can define the metric for the training. In this case we use datasets library ([documentation page](https://huggingface.co/docs/datasets/loading_metrics.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww1xEl0hXdEa"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzSMv1eWOBzR"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "UTKkhr86N8P_",
        "outputId": "69834899-b402-4d2f-b118-2d2e66217d41"
      },
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=compute_metrics      # custom metric\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 200\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 39\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39, training_loss=0.6486422220865885, metrics={'train_runtime': 50.889, 'train_samples_per_second': 11.79, 'train_steps_per_second': 0.766, 'total_flos': 79480439193600.0, 'train_loss': 0.6486422220865885, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcKWeNUupsEc"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai3p-Ce6qPO8"
      },
      "source": [
        " Furthermore, `Trainer` supports hyperparameter search using optuna or ray tune ([example code](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nVttGHcPGzG"
      },
      "source": [
        "On the other hand, Transformers allows to fine-tuning with native PyTorch/TensorFlow\n",
        "\n",
        "```python\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "model.eval()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwRn8XU-ZrUU"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88fRRQQWfm36"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIEOt3o2fVOs"
      },
      "source": [
        "# Generate some example testing dataset\n",
        "x_tests = test_texts[:4]+test_texts[-4:]\n",
        "y_true = test_labels[:4]+test_labels[-4:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODgY4_kCLThn"
      },
      "source": [
        "# Tokenize input\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "evaluation_encodings = preprocess_function(x_tests)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPh91S8gaZ7M"
      },
      "source": [
        "# Move to CUDA the input (because currently model is already in CUDA)\n",
        "evaluation_encodings = evaluation_encodings.to(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbjE1FkvLTkP"
      },
      "source": [
        "# Run prediction\n",
        "outputs = model(**evaluation_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40eptf6o0svd"
      },
      "source": [
        "# Get predictions\n",
        "logits = outputs.logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQB6Yyon0yHl",
        "outputId": "114f403e-b2c9-4174-b231-e2e5e3191c39"
      },
      "source": [
        "# Converte predictions to labels\n",
        "y_pred = [bool(logit.argmax()) for logit in logits]\n",
        "print(y_pred[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, True, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "PVRlS3dv03-M",
        "outputId": "5cd6089f-787a-430a-d9d6-c61452774cac"
      },
      "source": [
        "# Visualize prediction\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_true, y_pred, normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4cbc38c3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tTArtJXg6hP"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4gkDDUC3D4N"
      },
      "source": [
        "model.save_pretrained(\"path/to/repo/clone/your-model-name\")\n",
        "tokenizer.save_pretrained(\"path/to/repo/clone/your-model-name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpY_YW7XkWBq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vHfBJ0jkXmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}