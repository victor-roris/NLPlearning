{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPModel_MultiClass_Keras_CM2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/NLPModel_MultiClass_Keras_CM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAx0osp1c_h",
        "colab_type": "text"
      },
      "source": [
        "# NLP Model with Keras\n",
        "\n",
        "In this notebook we are going to train a custom Keras Model to predict categories of text. To vectorize the text we are going to use the multi-hot arrays from the `keras.preprocessing.text.Tokenizer`.\n",
        "\n",
        "Keras Tokenizer: https://keras.io/preprocessing/text/\n",
        "\n",
        "Notebook adapted from: https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8RIbrvL89x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kth0fn9nnyBW",
        "colab_type": "text"
      },
      "source": [
        "## Fetch data\n",
        "\n",
        "We use the sklearn direct dataset 20 news groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv_qGkzjcFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErEBZFLnJ8H",
        "colab_type": "code",
        "outputId": "60ae3a97-ec84-4095-e145-8b4c9f311b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_raw_df = fetch_20newsgroups(subset='train')\n",
        "test_raw_df = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKvmU9pnSGL",
        "colab_type": "code",
        "outputId": "cee86a89-1b5c-44e8-bbc4-5ef04767563b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(f'Number of raw training examples: {len(train_raw_df.data)}')\n",
        "print(f'Number of raw test examples: {len(test_raw_df.data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of raw training examples: 11314\n",
            "Number of raw test examples: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcsI_yLoSio",
        "colab_type": "code",
        "outputId": "e93d7bf9-e1f4-41c8-9aa6-596b710028b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "category_names = np.unique(np.array(train_raw_df.target_names))\n",
        "print(f'Number of different categories : {len(category_names)}')\n",
        "print(f'Category list: {category_names}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different categories : 20\n",
            "Category list: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQ_WAHane2l",
        "colab_type": "code",
        "outputId": "580cb860-c1ee-42cc-8ef5-0d331acafdc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "print('Example of entry:')\n",
        "print(f'\\t - LABEL : {train_raw_df.target[0]} - {train_raw_df.target_names[0]}')\n",
        "print(f'\\t - {train_raw_df.data[0]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of entry:\n",
            "\t - LABEL : 7 - alt.atheism\n",
            "\t - From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfRxZq_HpKrK",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ_wiaxHoFbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_raw_df.data\n",
        "y_train = train_raw_df.target\n",
        "\n",
        "x_test = test_raw_df.data\n",
        "y_test = test_raw_df.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_xK8v50qMq_",
        "colab_type": "text"
      },
      "source": [
        "## Model training\n",
        "\n",
        "We are going to use a model that doesn't use raw text as input. It use a vectorization of the text. For this, we are going to create a pipeline that allows combine the vectorizer and the model in the same structure.\n",
        "\n",
        "The vectorization is via TFIDF codification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDAYYYvV7vZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "c3235945-8400-4f23-c92d-c639d9833751"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Bidirectional, concatenate\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class KerasTextClassifier:\n",
        "    __author__ = \"Edward Ma\"\n",
        "    __copyright__ = \"Copyright 2018, Edward Ma\"\n",
        "    __credits__ = [\"Edward Ma\"]\n",
        "    __license__ = \"Apache\"\n",
        "    __version__ = \"2.0\"\n",
        "    __maintainer__ = \"Edward Ma\"\n",
        "    __email__ = \"makcedward@gmail.com\"\n",
        "    \n",
        "    OOV_TOKEN = \"UnknownUnknown\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 max_word_input, word_cnt, word_embedding_dimension, labels, \n",
        "                 batch_size, epoch, validation_split,\n",
        "                 verbose=0):\n",
        "        self.verbose = verbose\n",
        "        self.max_word_input = max_word_input\n",
        "        self.word_cnt = word_cnt\n",
        "        self.word_embedding_dimension = word_embedding_dimension\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch = epoch\n",
        "        self.validation_split = validation_split\n",
        "        \n",
        "        self.label_encoder = None\n",
        "        self.classes_ = None\n",
        "        self.tokenizer = None\n",
        "        \n",
        "        self.model = self._init_model()\n",
        "        self._init_label_encoder(y=labels)\n",
        "        self._init_tokenizer()\n",
        "        \n",
        "    def _init_model(self):\n",
        "        input_layer = Input((self.max_word_input,))\n",
        "        text_embedding = Embedding(\n",
        "            input_dim=self.word_cnt+2, output_dim=self.word_embedding_dimension,\n",
        "            input_length=self.max_word_input, mask_zero=False)(input_layer)\n",
        "        \n",
        "        text_embedding = SpatialDropout1D(0.5)(text_embedding)\n",
        "        \n",
        "        bilstm = Bidirectional(LSTM(units=256, return_sequences=True, recurrent_dropout=0.5))(text_embedding)\n",
        "        x = concatenate([GlobalAveragePooling1D()(bilstm), GlobalMaxPooling1D()(bilstm)])\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(128, activation=\"relu\")(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        \n",
        "        output_layer = Dense(units=len(self.labels), activation=\"softmax\")(x)\n",
        "        model = Model(input_layer, output_layer)\n",
        "        model.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "        return model\n",
        "    \n",
        "    def _init_tokenizer(self):\n",
        "        self.tokenizer = Tokenizer(\n",
        "            num_words=self.word_cnt+1, split=' ', oov_token=self.OOV_TOKEN)\n",
        "    \n",
        "    def _init_label_encoder(self, y):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(y)\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "        \n",
        "    def _encode_label(self, y):\n",
        "        return self.label_encoder.transform(y)\n",
        "        \n",
        "    def _decode_label(self, y):\n",
        "        return self.label_encoder.inverse_transform(y)\n",
        "    \n",
        "    def _get_sequences(self, texts):\n",
        "        seqs = self.tokenizer.texts_to_sequences(texts)\n",
        "        return pad_sequences(seqs, maxlen=self.max_word_input, value=0)\n",
        "    \n",
        "    def _preprocess(self, texts):\n",
        "        # Placeholder only.\n",
        "        return [text for text in texts]\n",
        "        \n",
        "    def _encode_feature(self, x):\n",
        "        self.tokenizer.fit_on_texts(self._preprocess(x))\n",
        "        self.tokenizer.word_index = {e: i for e,i in self.tokenizer.word_index.items() if i <= self.word_cnt}\n",
        "        self.tokenizer.word_index[self.tokenizer.oov_token] = self.word_cnt + 1\n",
        "        return self._get_sequences(self._preprocess(x))\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "            Train the model by providing x as feature, y as label\n",
        "        \n",
        "            :params x: List of sentence\n",
        "            :params y: List of label\n",
        "        \"\"\"\n",
        "        \n",
        "        encoded_x = self._encode_feature(X)\n",
        "        encoded_y = self._encode_label(y)\n",
        "        \n",
        "        self.model.fit(encoded_x, encoded_y, \n",
        "                       batch_size=self.batch_size, epochs=self.epoch, \n",
        "                       validation_split=self.validation_split)\n",
        "        \n",
        "    def predict_proba(self, X, y=None):\n",
        "        encoded_x = self._get_sequences(self._preprocess(X))\n",
        "        return self.model.predict(encoded_x)\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        y_pred = np.argmax(self.predict_proba(X), axis=1)\n",
        "        return self._decode_label(y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Yn2Osu77Qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "c44bb133-4775-473d-8832-27373bfd9d29"
      },
      "source": [
        "classifier = KerasTextClassifier(max_word_input=100, word_cnt=30000, word_embedding_dimension=100, \n",
        "                    labels=list(set(y_train.tolist())), batch_size=128, epoch=1, validation_split=0.1)\n",
        "classifier.model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 100, 100)     3000200     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_5 (SpatialDro (None, 100, 100)     0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 100, 512)     731136      spatial_dropout1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 512)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 512)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1024)         0           global_average_pooling1d_5[0][0] \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 1024)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          131200      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 128)          0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 20)           2580        dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 3,865,116\n",
            "Trainable params: 3,865,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cxbPmtp8jag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "61149561-73f6-490f-aed2-f0a45d2c738c"
      },
      "source": [
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10182 samples, validate on 1132 samples\n",
            "Epoch 1/1\n",
            "10182/10182 [==============================] - 201s 20ms/step - loss: 2.9127 - acc: 0.0802 - val_loss: 2.6791 - val_acc: 0.1148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwP-RiEswyxZ",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkg1ypWjkOd7",
        "colab_type": "code",
        "outputId": "801d43b8-c848-4c79-f024-58d03a61c336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.62      0.68       319\n",
            "           1       0.65      0.70      0.67       389\n",
            "           2       0.70      0.71      0.71       394\n",
            "           3       0.61      0.69      0.65       392\n",
            "           4       0.76      0.77      0.76       385\n",
            "           5       0.78      0.64      0.71       395\n",
            "           6       0.75      0.86      0.80       390\n",
            "           7       0.85      0.74      0.79       396\n",
            "           8       0.88      0.85      0.87       398\n",
            "           9       0.82      0.85      0.83       397\n",
            "          10       0.89      0.86      0.88       399\n",
            "          11       0.88      0.80      0.84       396\n",
            "          12       0.42      0.60      0.49       393\n",
            "          13       0.84      0.72      0.78       396\n",
            "          14       0.83      0.84      0.83       394\n",
            "          15       0.81      0.89      0.85       398\n",
            "          16       0.63      0.77      0.69       364\n",
            "          17       0.96      0.72      0.83       376\n",
            "          18       0.60      0.52      0.56       310\n",
            "          19       0.61      0.53      0.57       251\n",
            "\n",
            "    accuracy                           0.74      7532\n",
            "   macro avg       0.75      0.73      0.74      7532\n",
            "weighted avg       0.76      0.74      0.75      7532\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
