{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPModel-MultiClass-Keras CM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/NLPModel_MultiClass_Keras_CM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4tDCrJduy8c",
        "colab_type": "text"
      },
      "source": [
        "# NLP Multi-label Model with Keras Custom Model\n",
        "\n",
        "In this notebook, we are going to build a Custom Model using Keras to classify text in different categories. In particular, this model allows multicategory. More than one category can be predicted for one text.\n",
        "\n",
        "This notebook is adapted from :\n",
        " - https://stackoverflow.blog/2019/05/06/predicting-stack-overflow-tags-with-googles-cloud-ai/\n",
        " - https://www.youtube.com/watch?v=OHIEZ-Scek8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgcsonGWq4ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15430cfc-c432-4070-e7d2-c6387215c16e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import text\n",
        "import keras.backend.tensorflow_backend as K\n",
        "K.set_session"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function keras.backend.tensorflow_backend.set_session>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZqhR1KYqhLh",
        "colab_type": "text"
      },
      "source": [
        "* **Fetch data**\n",
        "\n",
        "We are going to use the Stack Overflow questions tags classification data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WMjReOQoBXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ea48487a-a592-4d57-b52f-e04e0936f22b"
      },
      "source": [
        "df = pd.read_csv('https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is causing this behavior  in our c# datet...</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>have dynamic html load as if it was in an ifra...</td>\n",
              "      <td>asp.net</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how to convert a float value in to min:sec  i ...</td>\n",
              "      <td>objective-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.net framework 4 redistributable  just wonderi...</td>\n",
              "      <td>.net</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trying to calculate and print the mean and its...</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                post         tags\n",
              "0  what is causing this behavior  in our c# datet...           c#\n",
              "1  have dynamic html load as if it was in an ifra...      asp.net\n",
              "2  how to convert a float value in to min:sec  i ...  objective-c\n",
              "3  .net framework 4 redistributable  just wonderi...         .net\n",
              "4  trying to calculate and print the mean and its...       python"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeG8CgzIqlQ5",
        "colab_type": "text"
      },
      "source": [
        "* **Clean data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6x53NKqeQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "3a7a79d9-055e-4c58-ad43-3395dfbac89c"
      },
      "source": [
        "# Remove entries with null tags \n",
        "df = df[pd.notnull(df['tags'])]\n",
        "\n",
        "# Get a fraction of the entries\n",
        "df = df.sample(frac=0.5, random_state=99).reset_index(drop=True)\n",
        "\n",
        "# Randomize the values\n",
        "df = shuffle(df, random_state=22)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Create a label column from the tags column\n",
        "df['class_label'] = df['tags'].factorize()[0]\n",
        "\n",
        "print(f'Number of labelled examples : {len(df)}')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labelled examples : 20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post</th>\n",
              "      <th>tags</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how do i move something in rails   i m a progr...</td>\n",
              "      <td>ruby-on-rails</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c#   how to output specific array searches   t...</td>\n",
              "      <td>c#</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>integer.parseint and string format with decima...</td>\n",
              "      <td>java</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>compilation problem while upgrading a website ...</td>\n",
              "      <td>.net</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>query to list out the records by comparing max...</td>\n",
              "      <td>sql</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                post  ... class_label\n",
              "0  how do i move something in rails   i m a progr...  ...           0\n",
              "1  c#   how to output specific array searches   t...  ...           1\n",
              "2  integer.parseint and string format with decima...  ...           2\n",
              "3  compilation problem while upgrading a website ...  ...           3\n",
              "4  query to list out the records by comparing max...  ...           4\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVX5IzPGWAE5",
        "colab_type": "text"
      },
      "source": [
        "* **Prepare data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQS4gJSb3f5",
        "colab_type": "text"
      },
      "source": [
        "  - *Encoding Tags As Multi-Hot Arrays*\n",
        "\n",
        "> Encoding labels is pretty simple using Scikit-learn’s MultiLabelBinarizer. Since a single question can have multiple tags, we’ll want our model to output multi-hot arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H4nyOVoHO_O",
        "colab_type": "text"
      },
      "source": [
        "Binarize the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIR_lhn77Mra",
        "colab_type": "code",
        "outputId": "7cfb3b26-7558-4cba-8a3b-4f7ff4ae8de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "tags_split = [tags.split(',') for tags in df['tags'].values]\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
        "\n",
        "print(f'Labels by entry in a binary matrix of = ({tags_encoded.shape[0]} examples) X ({tags_encoded.shape[1]} labels)')\n",
        "tags_encoded"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels by entry in a binary matrix of = (20000 examples) X (20 labels)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXF2vzCDqh0m",
        "colab_type": "code",
        "outputId": "ab7de03f-afbe-4a9d-d71d-c4fab4880de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(f'Classe labels: {tag_encoder.classes_}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classe labels: ['.net' 'android' 'angularjs' 'asp.net' 'c' 'c#' 'c++' 'css' 'html' 'ios'\n",
            " 'iphone' 'java' 'javascript' 'jquery' 'mysql' 'objective-c' 'php'\n",
            " 'python' 'ruby-on-rails' 'sql']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ3IKthaIuba",
        "colab_type": "text"
      },
      "source": [
        "Get the binary labels matrix for the training and evaluation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFncODU5BOCr",
        "colab_type": "code",
        "outputId": "5f978c83-ef21-46ef-faea-5ad125b638ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "num_tags = len(tags_encoded[0])\n",
        "train_size = int(len(df)*0.8)\n",
        "\n",
        "print(f'Number of labels : {num_tags}')\n",
        "print(f'Number of examples in the training dataset : {train_size}')\n",
        "print(f'Number of examples in the evaluation dataset : {len(df)-train_size}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels : 20\n",
            "Number of examples in the training dataset : 16000\n",
            "Number of examples in the evaluation dataset : 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK7zCFSJHqfl",
        "colab_type": "code",
        "outputId": "ed79ec57-75e8-4f4e-ff48-65691f711ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y_train = tags_encoded[: train_size]\n",
        "y_test = tags_encoded[train_size:]\n",
        "\n",
        "print(f'Binarize Label for each training example - binary matrix of = ({y_train.shape[0]} training examples) X ({y_train.shape[1]} labels)')\n",
        "print(f'Binarize Label for each evaluation example - binary matrix of = ({y_test.shape[0]} evaluation examples) X ({y_test.shape[1]} labels)')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binarize Label for each training example - binary matrix of = (16000 training examples) X (20 labels)\n",
            "Binarize Label for each evaluation example - binary matrix of = (4000 training examples) X (20 labels)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hel2m75HcDk6",
        "colab_type": "text"
      },
      "source": [
        " - *Text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqfAan_ZdHDT",
        "colab_type": "code",
        "outputId": "3cb5f904-6982-4ae2-fa4a-140a72a09931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_post = df['post'].values[:train_size]\n",
        "test_post = df['post'].values[train_size:]\n",
        "\n",
        "print(f'Number of training texts : {len(train_post)}')\n",
        "print(f'Number of evaluation texts : {len(test_post)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training texts : 16000\n",
            "Number of evaluation texts : 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poWUaGHyJb2K",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the texts\n",
        "\n",
        " > Imagine each input to your model as a bag of Scrabble tiles, where each tile is a word from your input sentence instead of a letter. Since it’s a “bag” of words, this approach cannot understand the order of words in a sentence, but it can detect the presence or absence of certain words. To make this work, you need to choose a vocabulary that takes the top N most frequently used words from your entire text corpus. This vocabulary will be the only words your model can understand.\n",
        " \n",
        " > Now we’re ready to create our Keras Tokenizer object. When we instantiate it we’ll need to choose a vocabulary size. Remember that this is the top N most frequent words our model will extract from our text data. This number is a hyperparameter, so you should experiment with different values based on the number of unique words in your text corpus. If you pick something too low, your model will only recognize words that are common across all text inputs (like ‘the’, ‘in’, etc.). A vocab size that’s too large will recognize too many words from each question such that input matrices become mostly 1s. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg8HqNVfIXvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import text\n",
        "class TextPreprocessor(object):\n",
        "    # Class to contain text processor functionalities\n",
        "    def __init__(self, vocab_size):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._tokenizer = None\n",
        "    def create_tokenizer(self, text_list):\n",
        "        tokenizer = text.Tokenizer(num_words = self._vocab_size)\n",
        "        tokenizer.fit_on_texts(text_list)\n",
        "        self._tokenizer = tokenizer\n",
        "    def transform_text(self, text_list):\n",
        "        text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
        "        return text_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEHgshBeJbBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instiate the Text Processor\n",
        "VOCAB_SIZE = 500\n",
        "processor = TextPreprocessor(VOCAB_SIZE)\n",
        "processor.create_tokenizer(train_post)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAEP9yvzdcY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the tokenized version of the training and evaluation texts \n",
        "X_train = processor.transform_text(train_post)\n",
        "X_test = processor.transform_text(test_post)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXsB2YhNdfha",
        "colab_type": "code",
        "outputId": "fd16b793-80e0-4438-abeb-39f61bb1211a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "print(f'Training data expresed in a matrix of tokens of: ({X_train.shape[0]} examples) x ({X_train.shape[1]} tokens) ')\n",
        "X_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data expresed in a matrix of tokens of: (16000 examples) x (500 tokens) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 1., ..., 0., 0., 1.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BumnbIYLd4W0",
        "colab_type": "code",
        "outputId": "64b5f33f-5e3b-4d72-de13-ee1355396d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "print(f'Training data expresed in a matrix of tokens of: ({X_test.shape[0]} examples) x ({X_test.shape[1]} tokens) ')\n",
        "X_test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data expresed in a matrix of tokens of: (4000 examples) x (500 tokens) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGoYCuFVXIaa",
        "colab_type": "text"
      },
      "source": [
        "* **Train model**\n",
        "\n",
        "> We’ve got our model inputs and outputs formatted, so now it’s time to actually build the model. The Keras Sequential Model API is my favorite way to do this since the code makes it easy to visualize each layer of your model. We can define our model in 5 lines of code. \n",
        "\n",
        "> This is a deep model because it has 2 hidden layers in between the input and output layer. We don’t really care about the output of these hidden layers, but our model will use them to represent more complex relationships in our data. The first layer takes our 500-element vocabulary vector as input and transforms it into a 50-neuron layer. Then it takes this 50-neuron layer and transforms it into a 25-neuron layer. 50 and 25 here (layer size) are hyperparameters, you should experiment with what works best for your own dataset. What does that activation='relu' part mean? The activation function is how the model computes the output of each layer. We don’t need to know exactly how this is implemented (thanks Keras!) so I won’t get into the details of ReLU here, but you can read more about it if you’d like. The size of our last layer will be equivalent to the number of tags in our dataset (in this case 5). We do care about the output of this layer, so let’s understand why we used the sigmoid activation function. Sigmoid will convert each of our 5 outputs to a value between 0 and 1 indicating the probability that a specific label corresponds with that input.\n",
        "\n",
        "> Notice that because a question can have multiple tags in this model, the sigmoid output does not add up to 1. If a question could only have exactly one tag, we’d use the Softmax activation function instead and the 5-element output array would add up to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_SU13fEeXnw",
        "colab_type": "code",
        "outputId": "27aa1a79-ff2b-4427-fcc3-5b53b2f974c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def create_model(vocab_size, num_tags):\n",
        "    # Create a keras sequential model\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(50, input_shape = (vocab_size,), activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "# Create model\n",
        "model = create_model(VOCAB_SIZE, num_tags)\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 20)                1020      \n",
            "=================================================================\n",
            "Total params: 56,170\n",
            "Trainable params: 56,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-E370AdJlY2",
        "colab_type": "code",
        "outputId": "c4c96a7e-617c-4cd6-d0ec-8065b41fa077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train, epochs = 20, batch_size=128, validation_split=0.1)\n",
        "print('Eval loss/accuracy:{}'.format(model.evaluate(X_test, y_test, batch_size = 128)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14400 samples, validate on 1600 samples\n",
            "Epoch 1/20\n",
            "14400/14400 [==============================] - 1s 43us/sample - loss: 0.2771 - acc: 0.9062 - val_loss: 0.1635 - val_acc: 0.9517\n",
            "Epoch 2/20\n",
            "14400/14400 [==============================] - 0s 30us/sample - loss: 0.1242 - acc: 0.9589 - val_loss: 0.1001 - val_acc: 0.9660\n",
            "Epoch 3/20\n",
            "14400/14400 [==============================] - 0s 30us/sample - loss: 0.0843 - acc: 0.9709 - val_loss: 0.0784 - val_acc: 0.9731\n",
            "Epoch 4/20\n",
            "14400/14400 [==============================] - 0s 30us/sample - loss: 0.0681 - acc: 0.9768 - val_loss: 0.0694 - val_acc: 0.9773\n",
            "Epoch 5/20\n",
            "14400/14400 [==============================] - 0s 32us/sample - loss: 0.0596 - acc: 0.9797 - val_loss: 0.0650 - val_acc: 0.9788\n",
            "Epoch 6/20\n",
            "14400/14400 [==============================] - 0s 31us/sample - loss: 0.0544 - acc: 0.9811 - val_loss: 0.0626 - val_acc: 0.9793\n",
            "Epoch 7/20\n",
            "14400/14400 [==============================] - 0s 30us/sample - loss: 0.0504 - acc: 0.9822 - val_loss: 0.0605 - val_acc: 0.9802\n",
            "Epoch 8/20\n",
            "14400/14400 [==============================] - 0s 31us/sample - loss: 0.0473 - acc: 0.9833 - val_loss: 0.0600 - val_acc: 0.9803\n",
            "Epoch 9/20\n",
            "14400/14400 [==============================] - 0s 31us/sample - loss: 0.0449 - acc: 0.9839 - val_loss: 0.0599 - val_acc: 0.9804\n",
            "Epoch 10/20\n",
            "14400/14400 [==============================] - 0s 31us/sample - loss: 0.0427 - acc: 0.9847 - val_loss: 0.0598 - val_acc: 0.9801\n",
            "Epoch 11/20\n",
            "14400/14400 [==============================] - 0s 29us/sample - loss: 0.0405 - acc: 0.9853 - val_loss: 0.0602 - val_acc: 0.9798\n",
            "Epoch 12/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0607 - val_acc: 0.9800\n",
            "Epoch 13/20\n",
            "14400/14400 [==============================] - 0s 29us/sample - loss: 0.0367 - acc: 0.9868 - val_loss: 0.0610 - val_acc: 0.9797\n",
            "Epoch 14/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0348 - acc: 0.9874 - val_loss: 0.0616 - val_acc: 0.9798\n",
            "Epoch 15/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0330 - acc: 0.9880 - val_loss: 0.0622 - val_acc: 0.9797\n",
            "Epoch 16/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0310 - acc: 0.9888 - val_loss: 0.0634 - val_acc: 0.9792\n",
            "Epoch 17/20\n",
            "14400/14400 [==============================] - 0s 29us/sample - loss: 0.0292 - acc: 0.9896 - val_loss: 0.0651 - val_acc: 0.9792\n",
            "Epoch 18/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0273 - acc: 0.9903 - val_loss: 0.0662 - val_acc: 0.9788\n",
            "Epoch 19/20\n",
            "14400/14400 [==============================] - 0s 27us/sample - loss: 0.0256 - acc: 0.9911 - val_loss: 0.0670 - val_acc: 0.9790\n",
            "Epoch 20/20\n",
            "14400/14400 [==============================] - 0s 28us/sample - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0681 - val_acc: 0.9789\n",
            "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0775 - acc: 0.9765\n",
            "Eval loss/accuracy:[0.07750917875766754, 0.97651243]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IreDMc4mQxpM",
        "colab_type": "text"
      },
      "source": [
        "* **Test our model locally**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebDSI96mPubI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomModelPrediction(object):\n",
        "\n",
        "  def __init__(self, model, processor):\n",
        "    self._model = model\n",
        "    self._processor = processor\n",
        "\n",
        "  def predict(self, instances, **kwargs):\n",
        "    preprocessed_data = self._processor.transform_text(instances)\n",
        "    predictions = self._model.predict(preprocessed_data)\n",
        "    return predictions.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPaxA5zqQ4fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_requests = [\n",
        "  \"Get the Row(s) which have the max value in groups using groupby. How do I find all rows in a pandas dataframe which have the max value for count column, after grouping by ['Sp','Mt'] columns?\",\n",
        "  \"I have a basic question below to help try get my head around functions in python (following the LPTHW tutorials in prep for uni). Could someone explain the syntax below, and whether I am correct with my assumptions? I understand that the print_two_again is the name of the function, but what is the purpose of having the arg1, arg2 in the parenthesis next to it? Is it to call the `steve` `testing` into the print command below? or do those strings go directing into the print command?\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqtS9mSbS02Q",
        "colab_type": "code",
        "outputId": "4354ae6b-c3e1-483d-b6ab-d0058cf384c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "classifier = CustomModelPrediction(model, processor)\n",
        "results = classifier.predict(test_requests)\n",
        "print(results)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.07212814688682556, 0.0014442205429077148, 9.882450103759766e-05, 0.37868261337280273, 0.00010716915130615234, 0.14114779233932495, 0.0005007386207580566, 0.0008513331413269043, 0.0007471442222595215, 1.1414289474487305e-05, 0.0007198154926300049, 0.012458831071853638, 3.3229589462280273e-05, 0.007745265960693359, 0.6430821418762207, 0.00032147765159606934, 7.2479248046875e-05, 0.008889257907867432, 0.010358572006225586, 0.02623969316482544], [2.473592758178711e-06, 2.294778823852539e-06, 2.086162567138672e-07, 1.767277717590332e-05, 0.0015439391136169434, 8.046627044677734e-07, 0.000331878662109375, 0.0, 0.00019782781600952148, 2.950429916381836e-06, 0.0009021461009979248, 6.705522537231445e-05, 3.606081008911133e-06, 2.5331974029541016e-06, 2.2649765014648438e-06, 0.0001264810562133789, 3.129243850708008e-05, 0.9987879991531372, 0.0008686482906341553, 2.682209014892578e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YsoL215t48E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "55087f2c-d2f4-40e0-d2e4-823a22583520"
      },
      "source": [
        "for i in range( len(results) ):\n",
        "  for idx, predprob in enumerate(results[i]): \n",
        "    if predprob > 0.5:\n",
        "      print(f'Example {i} - Predicted label : {tag_encoder.classes_[idx]} - prob {results[i][idx]}')\n",
        "      print()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example 0 - Predicted label : mysql - prob 0.6430821418762207\n",
            "\n",
            "Example 1 - Predicted label : python - prob 0.9987879991531372\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzEQFWP3v5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
