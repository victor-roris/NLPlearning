{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPModel_MultiClass_RandomForest_TFIDFVectorization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/mediumseries/blob/master/NLP/NLPModel_MultiLabel_RandomForest_TFIDFVectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAx0osp1c_h",
        "colab_type": "text"
      },
      "source": [
        "# NLP Model with Random Forest\n",
        "\n",
        "In this notebook we are going to train a Random Forest Model to predict categories of text. To vectorize the text we are going to use the TFIDF approach. \n",
        "\n",
        "Sklearn Random Forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "Sklearn TFIDF: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "Notebook adapted from: https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kth0fn9nnyBW",
        "colab_type": "text"
      },
      "source": [
        "## Fetch data\n",
        "\n",
        "We use the sklearn direct dataset 20 news groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv_qGkzjcFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErEBZFLnJ8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2ea3b917-5ca6-44b9-cbe4-43b87bc6178b"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_raw_df = fetch_20newsgroups(subset='train')\n",
        "test_raw_df = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKvmU9pnSGL",
        "colab_type": "code",
        "outputId": "5d7f7c8d-12d7-4a75-ecd8-b02e6f1004c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(f'Number of raw training examples: {len(train_raw_df.data)}')\n",
        "print(f'Number of raw test examples: {len(test_raw_df.data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of raw training examples: 11314\n",
            "Number of raw test examples: 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcsI_yLoSio",
        "colab_type": "code",
        "outputId": "e7831244-69e5-4f51-906e-63e08e3e4990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "category_names = np.unique(np.array(train_raw_df.target_names))\n",
        "print(f'Number of different categories : {len(category_names)}')\n",
        "print(f'Category list: {category_names}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different categories : 20\n",
            "Category list: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQ_WAHane2l",
        "colab_type": "code",
        "outputId": "9b947ed9-92e1-4d98-8830-11c9088c6671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "print('Example of entry:')\n",
        "print(f'\\t - LABEL : {train_raw_df.target[0]} - {train_raw_df.target_names[0]}')\n",
        "print(f'\\t - {train_raw_df.data[0]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of entry:\n",
            "\t - LABEL : 7 - alt.atheism\n",
            "\t - From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfRxZq_HpKrK",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ_wiaxHoFbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_raw_df.data\n",
        "y_train = train_raw_df.target\n",
        "\n",
        "x_test = test_raw_df.data\n",
        "y_test = test_raw_df.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_xK8v50qMq_",
        "colab_type": "text"
      },
      "source": [
        "## Model training\n",
        "\n",
        "We are going to use a model that doesn't use raw text as input. It use a vectorization of the text. For this, we are going to create a pipeline that allows combine the vectorizer and the model in the same structure.\n",
        "\n",
        "The vectorization is via TFIDF codification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43t_3fxkjlcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word Embedding via TFIDF - vectorization of the text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Pipeline execution to combine vectorization and model execution\n",
        "from sklearn.pipeline import make_pipeline \n",
        "\n",
        "# Definition of generic models\n",
        "from sklearn.ensemble import RandomForestClassifier  # Random Forest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp2uU1qdjqY2",
        "colab_type": "code",
        "outputId": "cbcded7e-616a-4081-b6f5-0f4c5baabe14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Train the vectorizer with the training documents to codify the text in a TFIDF representation \n",
        "vec = TfidfVectorizer()\n",
        "vec.fit(x_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AxuWNrZjyIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "estimator = RandomForestClassifier(n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Jh-PBMxSsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the pipeline with the vectorizer and the model\n",
        "pipeline = make_pipeline(vec, estimator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhMA8xkKxU5x",
        "colab_type": "code",
        "outputId": "fd071f32-0169-46e6-db55-269ab29e8ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# Train in the model\n",
        "pipeline.fit(x_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token...\n",
              "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features='auto',\n",
              "                                        max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=10, n_jobs=-1,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwP-RiEswyxZ",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkg1ypWjkOd7",
        "colab_type": "code",
        "outputId": "7831e7b8-c911-4427-c48b-578f41116e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = pipeline.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.61      0.55       319\n",
            "           1       0.30      0.50      0.37       389\n",
            "           2       0.45      0.61      0.52       394\n",
            "           3       0.34      0.42      0.38       392\n",
            "           4       0.39      0.45      0.42       385\n",
            "           5       0.57      0.48      0.52       395\n",
            "           6       0.58      0.68      0.63       390\n",
            "           7       0.60      0.60      0.60       396\n",
            "           8       0.76      0.73      0.75       398\n",
            "           9       0.61      0.65      0.63       397\n",
            "          10       0.76      0.74      0.75       399\n",
            "          11       0.75      0.75      0.75       396\n",
            "          12       0.43      0.27      0.33       393\n",
            "          13       0.60      0.44      0.51       396\n",
            "          14       0.73      0.64      0.68       394\n",
            "          15       0.62      0.76      0.68       398\n",
            "          16       0.62      0.60      0.61       364\n",
            "          17       0.87      0.66      0.75       376\n",
            "          18       0.69      0.32      0.44       310\n",
            "          19       0.48      0.21      0.29       251\n",
            "\n",
            "    accuracy                           0.56      7532\n",
            "   macro avg       0.58      0.56      0.56      7532\n",
            "weighted avg       0.58      0.56      0.56      7532\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWmsCQa618yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
